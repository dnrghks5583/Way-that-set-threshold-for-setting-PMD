{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "caltech101-resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcyHAZrBbWv0VJWsTTHsYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnrghks5583/Way-that-set-threshold-for-setting-PMD/blob/main/caltech101_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jWi9uCNk_xe",
        "outputId": "f94b779c-1db2-4063-83c7-4c020f7e7f95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6WogO7UlBgr"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "# training parameters\n",
        "batch_size = 32 # orig paper trained all networks with batch_size=128\n",
        "epochs = 100\n",
        "num_classes = 102\n",
        "data_augmentation = True\n",
        "\n",
        "# subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 9\n",
        "\n",
        "# model version\n",
        "# orig paper: version = 1 (ResNet v1), \n",
        "# improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "path = '/content/gdrive/My Drive/caltech101_pickle'\n",
        "image_size = (128, 128)\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 102"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieUuRL6NlHra"
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "with gzip.open('caltech101_x_trainData_128.pickle', 'rb') as f:\n",
        "    x_train = pickle.load(f)\n",
        "    \n",
        "with gzip.open('caltech101_x_testData_128.pickle', 'rb') as f:\n",
        "    x_test = pickle.load(f)\n",
        "    \n",
        "with gzip.open('caltech101_y_trainData_128.pickle', 'rb') as f:\n",
        "    y_train = pickle.load(f)\n",
        "    \n",
        "with gzip.open('caltech101_y_testData_128.pickle', 'rb') as f:\n",
        "    y_test = pickle.load(f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_7mb0Y4lKAc",
        "outputId": "7ecfd74a-f66b-4575-f9e3-ec0a6c911306"
      },
      "source": [
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# if subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('Model_Type : ' , model_type)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "# convert class vectors to binary class matrices.\n",
        "#y_train = to_categorical(y_train, num_classes)\n",
        "#y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_Type :  ResNet56v1\n",
            "x_train shape: (7316, 128, 128, 3)\n",
            "7316 train samples\n",
            "1829 test samples\n",
            "y_train shape: (7316, 102)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIRE70K9VGjD"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "    Arguments:\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "    Returns:\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=num_classes):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved\n",
        "    (downsampled) by a convolutional layer with strides=2, while \n",
        "    the number of filters is doubled. Within each stage, \n",
        "    the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "    Arguments:\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "    Returns:\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, in [a])')\n",
        "    # start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:\n",
        "                # linear projection residual shortcut\n",
        "                # connection to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=num_classes):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or \n",
        "    also known as bottleneck layer.\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, \n",
        "    the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, \n",
        "    while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have \n",
        "    the same number filters and the same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "    Arguments:\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "    Returns:\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA6jeqZvVJll",
        "outputId": "5c6ef983-4f5f-490b-a7ed-8fd2bb40176c"
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
        "              metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "# enable this if pydot can be installed\n",
        "# pip install pydot\n",
        "#plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 128, 128, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 128, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 16) 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 128, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 128, 128, 16) 0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 128, 128, 16) 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 16) 2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 16) 64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 16) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 16) 2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 16) 64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 128, 128, 16) 0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 16) 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 128, 128, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 128, 128, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 128, 128, 16) 2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 128, 128, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 128, 128, 16) 0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 128, 128, 16) 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 128, 128, 16) 2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 128, 128, 16) 64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 128, 128, 16) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 128, 128, 16) 2320        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 128, 128, 16) 64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 128, 128, 16) 0           activation_6[0][0]               \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 128, 128, 16) 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 128, 128, 16) 2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 128, 128, 16) 64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 128, 128, 16) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 128, 128, 16) 2320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 128, 128, 16) 64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 128, 128, 16) 0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 128, 128, 16) 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 128, 128, 16) 2320        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 128, 128, 16) 64          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 128, 128, 16) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 128, 128, 16) 2320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 128, 128, 16) 64          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 128, 128, 16) 0           activation_10[0][0]              \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 128, 128, 16) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 128, 128, 16) 2320        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 128, 128, 16) 64          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 128, 128, 16) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 16) 2320        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 128, 128, 16) 64          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 128, 128, 16) 0           activation_12[0][0]              \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 128, 128, 16) 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 16) 2320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 16) 64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 128, 128, 16) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 16) 2320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 16) 64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 128, 128, 16) 0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 128, 128, 16) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 128, 128, 16) 2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 128, 128, 16) 64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 128, 128, 16) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 16) 2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 128, 128, 16) 64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 128, 128, 16) 0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 128, 128, 16) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 32)   4640        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 64, 64, 32)   128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 64, 64, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 32)   9248        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 32)   544         activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 64, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 64, 64, 32)   0           conv2d_21[0][0]                  \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 64, 64, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 32)   9248        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 32)   128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 64, 64, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 64, 64, 32)   9248        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 64, 64, 32)   128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 64, 64, 32)   0           activation_20[0][0]              \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 64, 64, 32)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 64, 64, 32)   9248        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 64, 64, 32)   128         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 64, 64, 32)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 64, 64, 32)   9248        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 64, 64, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 64, 64, 32)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 64, 64, 32)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 64, 64, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 64, 64, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 64, 64, 32)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 64, 64, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 64, 64, 32)   128         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 64, 64, 32)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 64, 32)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 64, 64, 32)   9248        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 64, 64, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 64, 64, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 32)   9248        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 64, 64, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 64, 64, 32)   0           activation_26[0][0]              \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 64, 64, 32)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 64, 64, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 64, 64, 32)   128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 64, 64, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 64, 64, 32)   9248        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 64, 64, 32)   128         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 64, 64, 32)   0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 64, 64, 32)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 64, 64, 32)   9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 64, 64, 32)   128         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 64, 64, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 64, 64, 32)   9248        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 64, 64, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 64, 64, 32)   0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 64, 64, 32)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 64, 64, 32)   9248        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 64, 64, 32)   128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 64, 64, 32)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 64, 64, 32)   9248        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 64, 64, 32)   128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 64, 64, 32)   0           activation_32[0][0]              \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 64, 64, 32)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 64, 64, 32)   9248        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 64, 64, 32)   128         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 64, 64, 32)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 64, 64, 32)   9248        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 64, 64, 32)   128         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 64, 64, 32)   0           activation_34[0][0]              \n",
            "                                                                 batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 64, 64, 32)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 64)   18496       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 32, 32, 64)   256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 32, 32, 64)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 32, 32, 64)   36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 32, 32, 64)   2112        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 64)   256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 32, 32, 64)   0           conv2d_40[0][0]                  \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 32, 32, 64)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 64)   36928       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 64)   256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 64)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 64)   36928       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 64)   256         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 32, 32, 64)   0           activation_38[0][0]              \n",
            "                                                                 batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 64)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 64)   36928       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 64)   256         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 64)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 64)   36928       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 64)   256         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 32, 32, 64)   0           activation_40[0][0]              \n",
            "                                                                 batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 32, 32, 64)   36928       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 64)   256         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 64)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 32, 32, 64)   36928       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 32, 32, 64)   256         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 32, 32, 64)   0           activation_42[0][0]              \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 64)   0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 64)   36928       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 32, 32, 64)   256         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 64)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 64)   36928       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 32, 32, 64)   256         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 32, 32, 64)   0           activation_44[0][0]              \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 32, 32, 64)   0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 32, 32, 64)   36928       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 32, 32, 64)   256         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 64)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 32, 32, 64)   36928       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 32, 32, 64)   256         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 32, 32, 64)   0           activation_46[0][0]              \n",
            "                                                                 batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 32, 32, 64)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 32, 32, 64)   36928       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 64)   256         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 64)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 32, 32, 64)   36928       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 64)   256         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 32, 32, 64)   0           activation_48[0][0]              \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 64)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 64)   256         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 64)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 64)   36928       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 64)   256         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 32, 32, 64)   0           activation_50[0][0]              \n",
            "                                                                 batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 64)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 64)   36928       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 64)   256         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 64)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 64)   256         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 32, 32, 64)   0           activation_52[0][0]              \n",
            "                                                                 batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 64)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 4, 4, 64)     0           activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 102)          104550      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 965,670\n",
            "Trainable params: 961,606\n",
            "Non-trainable params: 4,064\n",
            "__________________________________________________________________________________________________\n",
            "ResNet56v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bay8BsPVfcr",
        "outputId": "fc7e4222-a61a-42fd-e684-49f16115935c"
      },
      "source": [
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [lr_reducer, lr_scheduler]\n",
        "#callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7AvdECbVgZA",
        "outputId": "b9690c7d-f5e6-4ea0-ea38-deb3497dfca2"
      },
      "source": [
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)\n",
        "\n",
        "steps_per_epoch =  math.ceil(len(x_train) / batch_size)\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "model.fit(x=datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "              verbose=1,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              callbacks=callbacks)\n",
        "\n",
        "\n",
        "# score trained model\n",
        "scores = model.evaluate(x_test,\n",
        "                        y_test,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=0)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 107s 304ms/step - loss: 4.6458 - acc: 0.2331 - val_loss: 4.1646 - val_acc: 0.2001\n",
            "Epoch 2/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 309ms/step - loss: 3.3787 - acc: 0.3584 - val_loss: 3.0874 - val_acc: 0.4297\n",
            "Epoch 3/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 2.8853 - acc: 0.4375 - val_loss: 2.9904 - val_acc: 0.4210\n",
            "Epoch 4/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 312ms/step - loss: 2.5774 - acc: 0.4836 - val_loss: 2.6155 - val_acc: 0.4943\n",
            "Epoch 5/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 2.3457 - acc: 0.5261 - val_loss: 2.4633 - val_acc: 0.5249\n",
            "Epoch 6/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 2.1542 - acc: 0.5631 - val_loss: 2.3047 - val_acc: 0.5424\n",
            "Epoch 7/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 2.0062 - acc: 0.5957 - val_loss: 2.0943 - val_acc: 0.5932\n",
            "Epoch 8/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 1.8512 - acc: 0.6219 - val_loss: 2.2929 - val_acc: 0.5549\n",
            "Epoch 9/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 1.7444 - acc: 0.6450 - val_loss: 2.2205 - val_acc: 0.5817\n",
            "Epoch 10/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 1.6311 - acc: 0.6646 - val_loss: 1.9018 - val_acc: 0.6211\n",
            "Epoch 11/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 1.5477 - acc: 0.6782 - val_loss: 1.7892 - val_acc: 0.6430\n",
            "Epoch 12/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 1.4767 - acc: 0.6960 - val_loss: 1.8036 - val_acc: 0.6512\n",
            "Epoch 13/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 312ms/step - loss: 1.4225 - acc: 0.7046 - val_loss: 1.8338 - val_acc: 0.6408\n",
            "Epoch 14/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 1.3121 - acc: 0.7247 - val_loss: 1.7533 - val_acc: 0.6468\n",
            "Epoch 15/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 1.2719 - acc: 0.7380 - val_loss: 1.7196 - val_acc: 0.6561\n",
            "Epoch 16/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 312ms/step - loss: 1.2311 - acc: 0.7423 - val_loss: 1.8132 - val_acc: 0.6457\n",
            "Epoch 17/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 1.1816 - acc: 0.7613 - val_loss: 1.8332 - val_acc: 0.6413\n",
            "Epoch 18/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 1.1100 - acc: 0.7694 - val_loss: 1.6493 - val_acc: 0.6720\n",
            "Epoch 19/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 1.0775 - acc: 0.7775 - val_loss: 1.7217 - val_acc: 0.6441\n",
            "Epoch 20/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 1.0689 - acc: 0.7839 - val_loss: 1.8934 - val_acc: 0.6408\n",
            "Epoch 21/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.9760 - acc: 0.8048 - val_loss: 1.8967 - val_acc: 0.6342\n",
            "Epoch 22/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.9773 - acc: 0.8040 - val_loss: 1.6408 - val_acc: 0.6752\n",
            "Epoch 23/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.9282 - acc: 0.8133 - val_loss: 1.8346 - val_acc: 0.6654\n",
            "Epoch 24/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 312ms/step - loss: 0.8906 - acc: 0.8215 - val_loss: 1.9269 - val_acc: 0.6342\n",
            "Epoch 25/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.8828 - acc: 0.8205 - val_loss: 1.8773 - val_acc: 0.6692\n",
            "Epoch 26/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.8474 - acc: 0.8308 - val_loss: 1.4741 - val_acc: 0.7223\n",
            "Epoch 27/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.8239 - acc: 0.8353 - val_loss: 1.6700 - val_acc: 0.6807\n",
            "Epoch 28/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.8297 - acc: 0.8319 - val_loss: 1.6341 - val_acc: 0.6987\n",
            "Epoch 29/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.7697 - acc: 0.8513 - val_loss: 1.5947 - val_acc: 0.7113\n",
            "Epoch 30/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.7727 - acc: 0.8473 - val_loss: 1.6244 - val_acc: 0.6840\n",
            "Epoch 31/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.7413 - acc: 0.8531 - val_loss: 1.5276 - val_acc: 0.7130\n",
            "Epoch 32/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.7246 - acc: 0.8602 - val_loss: 1.7025 - val_acc: 0.6889\n",
            "Epoch 33/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.6930 - acc: 0.8632 - val_loss: 1.7322 - val_acc: 0.7020\n",
            "Epoch 34/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.6944 - acc: 0.8678 - val_loss: 1.7280 - val_acc: 0.7042\n",
            "Epoch 35/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.6602 - acc: 0.8733 - val_loss: 1.6732 - val_acc: 0.6944\n",
            "Epoch 36/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.6873 - acc: 0.8663 - val_loss: 1.6817 - val_acc: 0.6840\n",
            "Epoch 37/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.6368 - acc: 0.8807 - val_loss: 1.8877 - val_acc: 0.6834\n",
            "Epoch 38/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.6432 - acc: 0.8764 - val_loss: 1.7582 - val_acc: 0.6840\n",
            "Epoch 39/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.6286 - acc: 0.8779 - val_loss: 1.5868 - val_acc: 0.7151\n",
            "Epoch 40/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.6057 - acc: 0.8894 - val_loss: 1.7332 - val_acc: 0.6884\n",
            "Epoch 41/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 312ms/step - loss: 0.5935 - acc: 0.8931 - val_loss: 1.6311 - val_acc: 0.7135\n",
            "Epoch 42/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5862 - acc: 0.8915 - val_loss: 1.7815 - val_acc: 0.7015\n",
            "Epoch 43/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5843 - acc: 0.8938 - val_loss: 1.6954 - val_acc: 0.7064\n",
            "Epoch 44/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5738 - acc: 0.8945 - val_loss: 1.6609 - val_acc: 0.7113\n",
            "Epoch 45/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5331 - acc: 0.9054 - val_loss: 1.8073 - val_acc: 0.6916\n",
            "Epoch 46/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 308ms/step - loss: 0.5516 - acc: 0.8999 - val_loss: 1.8599 - val_acc: 0.6829\n",
            "Epoch 47/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 312ms/step - loss: 0.5468 - acc: 0.9004 - val_loss: 1.7435 - val_acc: 0.7146\n",
            "Epoch 48/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5546 - acc: 0.8961 - val_loss: 1.6871 - val_acc: 0.7321\n",
            "Epoch 49/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5301 - acc: 0.9021 - val_loss: 1.6847 - val_acc: 0.7135\n",
            "Epoch 50/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5193 - acc: 0.9076 - val_loss: 1.7896 - val_acc: 0.7157\n",
            "Epoch 51/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5077 - acc: 0.9127 - val_loss: 1.6173 - val_acc: 0.7233\n",
            "Epoch 52/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5001 - acc: 0.9113 - val_loss: 1.9623 - val_acc: 0.6971\n",
            "Epoch 53/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4684 - acc: 0.9185 - val_loss: 1.9075 - val_acc: 0.6873\n",
            "Epoch 54/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.4885 - acc: 0.9159 - val_loss: 1.7890 - val_acc: 0.7119\n",
            "Epoch 55/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.5160 - acc: 0.9087 - val_loss: 1.9401 - val_acc: 0.6769\n",
            "Epoch 56/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4901 - acc: 0.9151 - val_loss: 2.0900 - val_acc: 0.6725\n",
            "Epoch 57/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4614 - acc: 0.9195 - val_loss: 1.8245 - val_acc: 0.7042\n",
            "Epoch 58/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4528 - acc: 0.9224 - val_loss: 1.9505 - val_acc: 0.6802\n",
            "Epoch 59/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4513 - acc: 0.9248 - val_loss: 1.7301 - val_acc: 0.7228\n",
            "Epoch 60/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.4379 - acc: 0.9318 - val_loss: 1.7778 - val_acc: 0.7212\n",
            "Epoch 61/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4258 - acc: 0.9319 - val_loss: 1.9181 - val_acc: 0.6987\n",
            "Epoch 62/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.4503 - acc: 0.9240 - val_loss: 1.8072 - val_acc: 0.7113\n",
            "Epoch 63/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.4552 - acc: 0.9177 - val_loss: 1.7727 - val_acc: 0.7173\n",
            "Epoch 64/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4404 - acc: 0.9247 - val_loss: 1.7449 - val_acc: 0.7250\n",
            "Epoch 65/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4519 - acc: 0.9225 - val_loss: 1.6478 - val_acc: 0.7283\n",
            "Epoch 66/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.4217 - acc: 0.9307 - val_loss: 1.8679 - val_acc: 0.7037\n",
            "Epoch 67/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4054 - acc: 0.9367 - val_loss: 1.6828 - val_acc: 0.7201\n",
            "Epoch 68/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4090 - acc: 0.9347 - val_loss: 1.8326 - val_acc: 0.7195\n",
            "Epoch 69/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 312ms/step - loss: 0.3959 - acc: 0.9364 - val_loss: 1.6181 - val_acc: 0.7326\n",
            "Epoch 70/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.4043 - acc: 0.9360 - val_loss: 1.7447 - val_acc: 0.7184\n",
            "Epoch 71/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.4054 - acc: 0.9319 - val_loss: 1.7552 - val_acc: 0.7294\n",
            "Epoch 72/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 312ms/step - loss: 0.3753 - acc: 0.9419 - val_loss: 1.7225 - val_acc: 0.7370\n",
            "Epoch 73/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.3978 - acc: 0.9363 - val_loss: 1.7285 - val_acc: 0.7261\n",
            "Epoch 74/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.3929 - acc: 0.9377 - val_loss: 1.6880 - val_acc: 0.7168\n",
            "Epoch 75/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.3786 - acc: 0.9425 - val_loss: 1.8536 - val_acc: 0.7190\n",
            "Epoch 76/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 312ms/step - loss: 0.4026 - acc: 0.9317 - val_loss: 2.2703 - val_acc: 0.6900\n",
            "Epoch 77/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.3930 - acc: 0.9328 - val_loss: 1.8413 - val_acc: 0.6982\n",
            "Epoch 78/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.3774 - acc: 0.9415 - val_loss: 1.9080 - val_acc: 0.7239\n",
            "Epoch 79/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.3770 - acc: 0.9386 - val_loss: 1.6916 - val_acc: 0.7376\n",
            "Epoch 80/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.3759 - acc: 0.9407 - val_loss: 1.9547 - val_acc: 0.7141\n",
            "Epoch 81/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.3763 - acc: 0.9408 - val_loss: 1.7100 - val_acc: 0.7315\n",
            "Epoch 82/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2971 - acc: 0.9661 - val_loss: 1.5571 - val_acc: 0.7583\n",
            "Epoch 83/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2729 - acc: 0.9748 - val_loss: 1.5340 - val_acc: 0.7682\n",
            "Epoch 84/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2480 - acc: 0.9806 - val_loss: 1.5605 - val_acc: 0.7682\n",
            "Epoch 85/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2520 - acc: 0.9799 - val_loss: 1.5600 - val_acc: 0.7687\n",
            "Epoch 86/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.2396 - acc: 0.9814 - val_loss: 1.5415 - val_acc: 0.7698\n",
            "Epoch 87/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2347 - acc: 0.9824 - val_loss: 1.5512 - val_acc: 0.7753\n",
            "Epoch 88/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2288 - acc: 0.9870 - val_loss: 1.5735 - val_acc: 0.7715\n",
            "Epoch 89/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2357 - acc: 0.9826 - val_loss: 1.5553 - val_acc: 0.7769\n",
            "Epoch 90/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2228 - acc: 0.9852 - val_loss: 1.5722 - val_acc: 0.7720\n",
            "Epoch 91/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2138 - acc: 0.9893 - val_loss: 1.5558 - val_acc: 0.7742\n",
            "Epoch 92/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.2135 - acc: 0.9876 - val_loss: 1.6002 - val_acc: 0.7709\n",
            "Epoch 93/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2101 - acc: 0.9895 - val_loss: 1.5706 - val_acc: 0.7758\n",
            "Epoch 94/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2098 - acc: 0.9874 - val_loss: 1.5434 - val_acc: 0.7758\n",
            "Epoch 95/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.2071 - acc: 0.9887 - val_loss: 1.5715 - val_acc: 0.7731\n",
            "Epoch 96/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.2054 - acc: 0.9881 - val_loss: 1.5818 - val_acc: 0.7731\n",
            "Epoch 97/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.2001 - acc: 0.9885 - val_loss: 1.5788 - val_acc: 0.7747\n",
            "Epoch 98/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 70s 307ms/step - loss: 0.1955 - acc: 0.9904 - val_loss: 1.6305 - val_acc: 0.7715\n",
            "Epoch 99/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.1965 - acc: 0.9892 - val_loss: 1.5750 - val_acc: 0.7791\n",
            "Epoch 100/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 71s 308ms/step - loss: 0.1921 - acc: 0.9893 - val_loss: 1.5790 - val_acc: 0.7764\n",
            "Test loss: 1.5790202617645264\n",
            "Test accuracy: 0.7763805389404297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD5fammJlQn5",
        "outputId": "e0acfc9b-73c4-4d2a-c30c-312ee41ed5c3"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58/58 [==============================] - 4s 75ms/step - loss: 1.5790 - acc: 0.7764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5790202617645264, 0.7763805389404297]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL5ZVMO2LU1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc6719b-2c75-426b-b59d-10d49951118b"
      },
      "source": [
        "import tensorflow\n",
        "\n",
        "cce = tensorflow.keras.losses.categorical_crossentropy(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    from_logits = False,\n",
        "    label_smoothing = 0)\n",
        "cce = cce.numpy()\n",
        "print(cce)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.2872155e-03 1.1920930e-07 1.1920930e-07 ... 1.0638627e-01 9.0904301e-03\n",
            " 1.0506958e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xegYf1h2GJ5D"
      },
      "source": [
        "def classification_Cce(cce, y_test, y_pred) :\n",
        "  c = []\n",
        "  m = []\n",
        "  c_i = []\n",
        "\n",
        "  for i in range(len(y_test)) :\n",
        "    if np.argmax(y_test[i]) == np.argmax(y_pred[i]) :\n",
        "      c.append(cce[i])\n",
        "      c_i.append(i)\n",
        "    else :\n",
        "      m.append(cce[i])\n",
        "\n",
        "  return c, m, c_i"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFxioRCHHV4z",
        "outputId": "26f94dd9-1239-46ec-e7e7-e4008c9b71b0"
      },
      "source": [
        "collect_Cce, missclassification_Cce, collect_Idx = classification_Cce(cce, y_test, y_pred)\n",
        "print(len(collect_Cce))\n",
        "print(len(missclassification_Cce))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1420\n",
            "409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJc72ue5906W"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TuUqxGNmFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d02579af-2bd2-4e72-bf13-7da2caa0ffbb"
      },
      "source": [
        "x_value = []\n",
        "for i in range(len(collect_Cce)) :\n",
        "  x_value.append(i)\n",
        "\n",
        "plt.scatter(collect_Cce, x_value)\n",
        "plt.title('Collected data cross entropy')\n",
        "plt.ylabel('index')\n",
        "plt.xlabel('cross entropy')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGUHUdl8OHaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9184400f-9d50-4c19-e584-002334678d8c"
      },
      "source": [
        "X_value = []\n",
        "for i in range(len(missclassification_Cce)) :\n",
        "  X_value.append(i)\n",
        "\n",
        "plt.scatter(missclassification_Cce, X_value)\n",
        "plt.title('Missclassification data cross entropy')\n",
        "plt.ylabel('index')\n",
        "plt.xlabel('cross entropy')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29fZxdVXXw/12Z3MAkWiZISmEgBAWTEpEEUqTGtiY8goqGVMSoqGhRqj98IdLUYKmECg/RVEGr1R+K5bWQQDACotES0EoFSZxEDJDKezKABGEikEmYTNbzxznn5syZ837P6737+/nkk7nnnnvOPi97rbXXXnstUVUMBoPBYAAYU3YDDAaDwVAdjFIwGAwGQxOjFAwGg8HQxCgFg8FgMDQxSsFgMBgMTYxSMBgMBkMToxTaCBH5toj8c07HVhE5LKdjnyYiP3F9ni0ivxORF0Vkvoj8SEROz+G8ud0vz3neLCJb8j6PwZAFYtYpVB8ReQw4EDhQVZ91be8DZgCHqupjObdBgcNV9aE8z2Of63bgZlX9WobH/DDwUVV9U1bHTHDuNwPXqOpBMfb9MCW1s0qIyBTgUaChqrvKbU1nYUYK9eFR4H3OBxE5EhhfXnNy5RBgY9mNaGfEotb9X0TGlt2GdqTWL0WHcTXwIdfn04Gr3DuIyBUicqH9934icquIDIjIcyLy344QEJHPiUi/iLwgIptE5Hh7e5eIfF5EHra/WyciB3sbIiIniUifiPxRRDaLyBLXd3uLyDUi8gf73PeKyP72dx8WkUfsYz8qIqe5tv/C/vth4NXALbb7aC8RuVNEPuo6x8dE5AH7OPeLyNH29sWutt8vIn9rb/9z4NvAX9rHHPDeL9dxH7Lv180icqDrOxWRj9turQER+aaIiN+DEpFu+9jPi8j9wF94vk/azsD7HXD+k0Vkvb3/wyLyVnv7nSJykYjcBWwHXi0ib7Sf0Tb7/ze6jhP0vA4TkZ/Zv3lWRJaHtOU4Efkf+55tsEdNznd3isgXReQu+xw/EZH97K9/bv8/YN+Lv7Tbc5eIXCIifwCWiMg+InKViGwVkcdF5DzXe+7s/w27rQ+63vVTRWSdp62fFZEfhN3bjkBVzb+K/wMeA/4PsAn4c6AL2IJlUSswxd7vCuBC+++LsQRMw/73V4AAU4HNWK4ogCnAa+y/FwH32fsIcBTwKvs7BQ6z/34zcCSWUfF64PfAfPu7vwduwRrFdAHHAH8CTAD+CEy19zsAmG7//WHgF97rdX2+E8ulAnAq0I8laAU4DDjE9d2BdrsWAC8BB/idw+d+zQWeBY4G9gL+Dfi5a18FbgV6gMnAVuCtAc9rKfDfwL7AwcBvgS2u75O2M/B++5z7WGAb8BZ7/15gmus+PgFMB8YC+wPPAx+0P7/P/vyqiOd1HfBP9vH3Bt4U0JZe4A/A2+1932J/nuRqz8PAa4Fu+/NS13upwFjX8T4M7AI+Zbe3G8sw+gHwSvs3/wuc4dl/IVYfWGDfm33tZ/wc8Oeu4/cBp5Td38v+Z0YK9cIZLbwFeABLOAYxhNWRD1HVIVX9b7Xe/GGsDnGEiDRU9TFVfdj+zUeB81R1k1psUNU/eA+sqneq6n2qultVf4MlJP7Gdd5XYSmQYVVdp6p/tL/bDbxORLpV9SlVTeMi+ijwZVW9127jQ6r6uN2uG1T1Sbtdy4HfYQnJOJwGfE9Vf62qO4FzsSz2Ka59lqrqgKo+AdyBNZ/jx3uAi1T1OVXdDHzd/WXSdkbcby9n2NfxU3v/flV90PX9Faq6US0//QnA71T1alXdparXAQ8C77T3DXpeQ1gGyYGqukNVfxHQlg8At6nqbXZbfgqsxVISDv+hqv+rqoPACoLvqcOTqvpvdvtfBt4LnKuqL6g1r/YVLCXn8Axwqd0HlmMZVifZz3i53UZEZDqWUrk14vxtj1EK9eJq4P1YFtBV4buyDHgI+IntAlgMoNZE8dnAEuAZEbne5SY5GMtyC0VE3iAid9hD9m3AxwFn2H81sBq4XkSeFJEv28rnJSxL7ePAUyLyQxGZFvvK9xDYRhH5kO02GbBdL69ztSuKA4HHnQ+q+iKWVdvr2udp19/bgVeEHGuz6/Pj7i+TtjPifnuJeobudo24ZldbeyOe1z9ijdJ+JSIbReTvAs51CHCqc532tb4Jy1hxiHtP/dq/H9YIwH0NjzPymfXbxpD7e+d9vxJ4v+0G/CCwwlYWHY1RCjXCtogfxbK0borY9wVVPUdVXw3MAz7r+FNV9T/Vim5x3E9fsn+2GXhNjKb8J3AzcLCq7oPlphL72EOqeoGqHgG8EXgH9lyIqq5W1bdgCYUHge/Evvg9+LZRRA6xj/dJLJdXD5bbxvH7R4XZPYl1P5zjTcAa8YSNxoJ4Cks4O0xusZ2B99uHqGfoPv6Ia3a1tR+Cn5eqPq2qH1PVA7Hchf8u/uHKm4GrVbXH9W+Cqi4NaZ9fO4O2P8ueUcuo9tv0euZ+JmNdN6p6N9Zo46+wjK2rY7Sr7TFKoX6cAcy1LblAROQd9oSgYPlRh4HdIjJVROaKyF7ADmAQy00A8F3giyJyuFi8XkRe5XP4VwLPqeoOETkWq0M5550jIkeKSBeWT3rIPu/+9gToBGAn8KLrvEn4LvAPInKM3cbDbEE7AUtgbLXb8REsC9zh98BBIjIu4LjXAR8RkRn2vfm/wD2aLtR3BXCuiEwUkYOwfOAOadoZeL99uNy+juNFZIyI9IaMyG4DXisi7xeRsSKyADgCuDXsedmTtE547fP29fg9y2uAd4rIiWIFMewt1pqNyNBcrPuzGyvowBdVHca61xeJyCvt9+Cz9nkd/hT4tIg0RORUrDm521zfXwV8AxgKcYN1FEYp1AxVfVhV18bY9XDgv7A68y+Bf1fVO7DmE5ZiWVlPY3Wac+3ffBWrk/0ES6BfjjWZ5+X/A/5FRF4AvmD/xuHPgBvt3z8A/AzLAhuD1WGfxJrg+xvgE7Eu2oWq3gBchGU9vwCsAvZV1fux/Mm/xBKsRwJ3uX66BivM9WkReRYPqvpfwD8DK7Es/ddg+avTcAGWm+JRrHvZtEBTtjPsfnuv41fAR4BLsIyBnzF6NODs+weskdw5WK6yfwTeodZamLDn9RfAPSLyItYI5jOq+ojP8TcDJwOfxxLym7GCGSLljqpux3rOd9mup+MCdv0U1kT9I8AvsN6L77m+vwerLzxrH+/dnnmyq7GUsluRdDRm8ZrBYGhLJMZCQBHpxpqMPlpVf1dU26qMGSkYDIZO5hPAvUYh7MGsCDQYDB2JWOljBJhfclMqhXEfGQwGg6GJcR8ZDAaDoUmt3Uf77befTpkypexmGAwGQ61Yt27ds6o6ye+7WiuFKVOmsHZtnOhMg8FgMDiIiHclexPjPjIYDAZDE6MUDAaDwdDEKAWDwWAwNDFKwWAwGAxNjFIwGAwGQ5NaRx8ZDEWyqq+fZas38eTAIAf2dLPoxKnMn9kb/UODoUYYpRBAKwLACI/2Y1VfP+fedB+DQ8MA9A8Mcu5N9wGYZ2toK4xS8KEVAWCEh0W7KcZlqzc1n6nD4NAwy1ZvqvV1eWm352ZIjlEKPrQiADpFeITRjorxyYHBRNvrKFz9ntuiGzew5OaNbBscqs11GFojd6VgV+Bai1Ur9R0icihwPVapw3XAB1X1Zbva1VXAMVgFPxakrHrVMkkFQJx9+gcGOXTxDzuiY7WjYjywp5t+n2fbM77B7KVrRgh/oJZK0e+5DQ0rA4NDQH2uw9AaRUQffQarApfDl4BLVPUwrFJ+Z9jbzwCet7dfwp66wYVzYI9fsbHg7XH3UfZ0rFV9aUr/xmdVXz+zl67h0MU/ZPbSNbmfz02YUi2zXa2w6MSpdDe6RmxrdAkv7thF/8DgiGd7wS0bA5VilYlj9NThOgytkatSsGuxnoRVVxe7XvBcrHKNAFeyJ5f5yfZn7O+P9xTcLoRVff28tHPXqO3dja6mFRiGn/DwknfHctwAXmFVlAAOUow94xultqsV5s/s5eJ3HUlvTzcC9PZ0M2HcWIZ2j0w9Pzg0zPPbh3yPEUfolkkcoweqdx11NTSqSt4jhUux6r46Rb1fBQyoqiN1twDOOLQXq4Yr9vfb7P1HICJnishaEVm7devWTBvrCFNnuOwwcXyDi991ZKwhs1d4BJFnxwpz3xSBn2LsbnShSuUt6DABM39mL3ctnsujS0/irsVz2TboL/yDiCt0yyDIGPKjStdRtgHUjuSmFETkHcAzqrouy+Oq6mWqOktVZ02a5Jv5NTV+w36A8ePGJvKhuoVHbwuuqLS0MieSBX5W9cXvOjJQiFbF8kwqYAJHRN0NX6UYZ6RZBkHG0IRxXTTGjDRt0l5HXtZ82QZQGeQ9Mspzonk2ME9E3g7sDfwJ8DWgR0TG2qOBgwDnivqBg4EtIjIW2AdrwrkQVvX15zLsX3Ti1BGTjpC/gAiaFC3Swps/s3eUIl22elPp7Qoj6QR50LNdMm9683h+0Ud+kUlh++eN33UD9Iwfx6ITp7bcrjyj0co2gIqmiMi+3JSCqp4LnAsgIm8G/kFVTxORG4B3Y0UgnQ78wP7JzfbnX9rfr9ECa4WGWRY94xupj+s8qCI7fBmKKA5ltysqTDSpgIl6tn7P2Dfs84YNIFakj7OtyCifsOv2U+5JyTMarQoGUJEUEdlXxjqFzwHXi8iFQB9wub39cuBqEXkIeA54bx4nDxIMYZbFizt2saqvP/VNz6JjJT0flGd5VrFdq/r6WXTjhhGCd9GNG0a0K42ASfpsfcM+d4+2fYoM4c1bsOZpzZdtaBRNESOjQpSCqt4J3Gn//QhwrM8+O4BT82xH2NArqGOA1WnrFmPvCCtHCS5cvp5lqzeVrhyKVpAOF9yysakQHIaGlQtu2dhsTxoBk3SRWpLOW5QLJG/BmqfSqaoBlBdFjIw6Kktq2NArKpS0jj5KE5mxh6D5oue3DzXvR9AEeZCASXN/k7gii3KBJL3upARFo2WldLxRYe2qECD/ewkdluYiyncKcM6KDQz7TGW4O2hdUhi048riPHD775OMZJLe31V9/by4Y3TY5xiBrjEyYiSTpwsk6P3N653oNGs+T4q4lx2lFKKGXs6NDRtK1ymvT6dFZoTR090YFXLpkFZRJr2/y1Zv8p0/ULVcWV0iDKvSm6PQPG/VfVx79xM4rSjq/S3LbdiO5H0vO8p9FGfoFTWUrlNcdJD7QaHjVn4umTd9VMy9mzSKMmk6lKBzOAJ6WLX5Pqbt9GEx7Kv6+kcoBIeqvr+GcuiokULcoVeYJq6q9e12CezT3UDE8pcLjBICUO0RTh4kcQ/GJekEbVgwg0Mr7r2oUeyy1Zt83wUo//01VIeOUgrQ+tCrinHRXmHgdpMoBCqGOAKoLvMncYjjHkxzvLj3x0+J+JFWQEfNcYQdt13j+utGFfpbxymFVskjfK/VFyFoRapD2ArAMEFRp/mTuGQ9UZfEyPCee4w9h+DFK6Djvh9Ro9ggg0agbeP660RV+ptRCgmZP7OXtY8/x3X3bGZYrcnBU45JP/rI4kVoZegfZiGWHb2Ul9VU5qSn+9zeZw+jDYwk70fUKNbPoBHgtOMm11bJtxNl9zeHjppozoJVff2sXNfftPCGVVm5rj/1pG0WE9dxhv5pkrSVOX/SCWss4qwPSPJ+RAVSOOeb6For0d0Yw60bnjJppytAVeYrzUghIUGd9IJbNqayarN4EaJ81XGStPlR5vxJVaymvIkatSR5P+K6xnYM7W7+vX1oN9vtz+3gHqwzcftb3vMOHakUWrmpQZ30+e1DzVWzSTpXFoLXKwyc6KOB7aPr6iZ5ecrMK1MVq6lskr4fUUomav6pnRRvFSZtkxCnv9U6S2pVafWmxgkrhPidKyvBm4efvMiVqN4O3DO+4Zuaoh2iZJIIq6wVcyt1xutEVSZtkxCnv7VrltRSafWmxg0rhHidq+opAIqYlPXrwI0xQqMrOPVDla3AsLYlFVZZvx9xjJp2ULx1dT9m6U5MS8cphSQ3NaxzBxWMcePXuYrOO1MHgtJJ93Q3mLDX2FH3qspWYJwFZEmFVZbvR5z5p3YIT21X92MR83wdpxSSTOaEde75M3uZvXRNoGLw61xVFmZlEtRRtw0Osf78E0Ztr7IVmHYBWRbCalVfP0tu3thcvDhxfIPz3zl9xD3xjjx6xjdQte511UZcrVDFRaZZUMQ8X25KQUT2Bn4O7GWf50ZVPV9ErgD+Bthm7/phVV0vIoJVrvPtwHZ7+6+zblfcmxpH8ARZXd7O6IwO/F7SooVZFd0uSTtwla3AtAvIWhVWq/r6WXTDhhEJ957fPjSqkJDzd9nPPG/atfhO3bOk7gTmquqLItIAfiEiP7K/W6SqN3r2fxtwuP3vDcC37P8zJe5NjSN44hzLb4FS2DHzpIiRShqlk1UOoSpYgWkXkM2ZNqml8wZlYB0arl+BqCyo+lxdK+St1POs0azAi/bHhv0vLOPCycBV9u/uFpEeETlAVZ/Kum1xbmpcwdNqCKDfMfMib7dLWqWTRQ6hVqzALEZP7tGgN9eUdwHZ2sefG5GtVIGV6/qZdci+qZ9DmGFRhRFUGXTCiCgPcp1TEJEuYB1wGPBNVb1HRD4BXCQiXwBuBxar6k6gF9js+vkWe9tTnmOeCZwJMHny5NzanpXgieqQRQ5p83a7JFE6foL4rsVzY50nSyswi9GT9xjuJIR+tRHueHBrYPrqPKKKqjCCMmRHrRevqeowMENEeoDvi8jrgHOBp4FxwGXA54B/SXDMy+zfMWvWrLCRR0t4o4y6REakF4j7EMI6a1QxlawfflUKtGchiLOyArMYPfkdw1EIfoouD+W86MSpo+YUABpdUns/umEPRbiAC8l9pKoDwB3AW1X1KbXYCfwHcKy9Wz9wsOtnB9nbSmP+zN5mPhkn15HzEM5bdV9gMRM3QfloLl0wI7SebNzcP2FFVeK2JcsC7XG2V6lQURYCOukxkhbnicP8mb0sO/Uoerr35DWaOL7BsncfZVwobUQRfSfP6KNJwJCqDohIN/AW4EvOPIEdbTQf+K39k5uBT4rI9VgTzNvymE9IStBDiFvSMK2rI8qC9YYfRrWjlbbEZdGJU1l044YRC878LNUqRQ9lMXpKeoy8ImOMD739qfvitQOAK+15hTHAClW9VUTW2ApDgPXAx+39b8MKR30IKyT1Izm2LTZRJRQdwlwOaTpr2MMPi2gqciEUjK74NuyNgPFx8FUpeigLAZ30GGmVcxXDiQ3FUkTfEfUp8lEXZs2apWvXrs31HGEL1LwI8OjSk3I/b1dAcZY82hFGnHBbsNq7W7UpyMC/+pk3bXRRZBl9lJfADqq9UNY9M5RDVu+BiKxT1Vm+3xmlEI7fQwgqbxk0seh3zCgBElfg+hG3HXEJam8ShengvMDQnjHkeRF0r7N+1obqk4UBEqYUOi7NRVL8opCGVUNj0cOIGz2QJMeSm6xDXMPam8aP6bi3oibZjcIYSZXmYQzlkvfcUUdWXksSsQPWQ5gzbRICTbeNE4sO/hWzgkgSPTB/Zi93LZ7bPE8c9hqb7SMNa29aP2acutDtXHEtDXlELBkMfnScUkgjdFb19Y+INnJwx6LH1dxBArF/YDBQUQV1/C6x1IVbaQwMDmUqRMMsVL8Q18YYYeL4BuJqn5e0daE7mbzDiQ0Gh45TCmmEzrLVmwLzcyQdvgcJRIFARRUkEL7ynqPo7ekOjITKgh5XPV/v9vkzR9cYXnbqUfR94QQeXXoSX3nPUaXVhU46Gqw6fvfaTDKnp93ejyzpuDmFNEIn7Lukw/eghGh+gv2cFRtYuHw9B/Z0c8oxvdzx4NZRfvaFy9cnbnMSguIQnO1h/s00oZdZhNy1a4ryJL5kMy8TTLu+H1nRcUohjdAJ+o1AqrKZMFJQBk0ku1dRX3P3E/R0N7hkwYwRL27eccvbXIvj4mz3knRSLIt1A1Wut+AlD+FthF44dXo/yqDj3EdxfbPu4eVLO3fR6BrpHxfgtOMmp3qJnAnkR5eexF2L59IbU4D7zRdUJXVFVmThJqlLpE5ek+pmXiacurwfZdFxI4U0NRAGBoeaE6gD27OpUOVdCeytRxyE16IpInVF0cVKWg25q9KK6TDysliN0Asn6P0Imj/rNDpOKUC6GghDu5Xx48bS94XR5SGTEqV0xkSsWPZ27jzjlutYrKQuVbfyEt51UYpF4XXRzZk2ieX3bh5lhL24Yxer+vozcd/Vqb946UilEEVU3qFWH3iU0lnV18/ZARPIUHznrluitboosryEd12UYp4EFT3qHxhk5bp+GmNGj8yHdrdepa4d5nOMUvAhbHiZxQOPshDnz+wdlQHVIc3kdidSB0WWRnjHMUryVopVt4T9ih65ybM0bjtMYhul4ENQZ1Ud/UJ5Q0fjdJA4FuKSedN9Q1fTTm4bqkdS4Z3ECs1LKdbBEo5TAjeIVkdpRczn5K2UOy76KA5BETBBYZjDqomiR/wihsB6cc5btaeDedtwyYIZXDj/yBavzlAlvJFoSee6io4qqkIboogjgHu6G7lE7eUdrVdEGhgzUgjAz9KKk5wuzlDR+e6fvn8fL728p4MpcM3dTwBw4fwja+ECMRRHq1ZoFhZmHpZwUWVnHbobXSyZNx3I3sWW93xOEe6p3EYKIrK3iPxKRDaIyEYRucDefqiI3CMiD4nIchEZZ2/fy/78kP39lLzalpYgC99LnA4yf2YvO4Z2+3533T2bE7fN0P60YoVmVd41a0s4D8vXr5/6Ja9MMkqLS97pSOpeeW0nMFdVXxSRBvALEfkR8FngElW9XkS+DZwBfMv+/3lVPUxE3gt8CViQY/sS4/UBB4WOxu0gQWGnYeGohs6lFSs0yu0TFKnjnS/I2hLOw/ItO/oszxF+z/gGz28f7cbOco1FbkpBreo9L9ofG/Y/BeYC77e3XwkswVIKJ9t/A9wIfENERCtWBcj9wIOqIMXtIEEV1MaIVVSlqtEdhnJoRdiFZeeNitTJc7FkXpZvu7pedwZMoAdtT0Oucwp2feZ1wGHAN4GHgQFV3WXvsgVwnlwvsBlAVXeJyDbgVcCzebYxiCJC/973hoObcwgjUJo+0SpGd1SRqodJpiHomtJcV5CfvUskMlInz8WSZqFdMrYHuJyDtqchV6WgqsPADBHpAb4PTGv1mCJyJnAmwOTJk1s9nC9Zhv6FCSsnkui6ezYzrEqXCOPGCoOeB1y3OOeiqUOYZFKyvqYgt0+c0M08BbRfuxpdwks7d3Ho4h+2jYKvE4WEpKrqAHAH8JdAj4g4yuggwJlR6gcOBrC/3wf4g8+xLlPVWao6a9KkSbm0N6uwuziTaBfOP5KHL347jy09iYcvfnvg5LPXWmuXfPBZXEcdwiSTkvU1BU2ARiVjLCLPlbtdE8c3QK3UL6byXjnkNlIQkUnAkKoOiEg38BasyeM7gHcD1wOnAz+wf3Kz/fmX9vdryppPSOvn9I4Ktr+8K/EkWpzhdLtYxlldR5USwGXlxsrjmoJGtUH1PXoLstLd7Zq9dM2oiVQzUt5DT3fDN9NBT3cNJpqBA4Ar7XmFMcAKVb1VRO4HrheRC4E+4HJ7/8uBq0XkIeA54L05ti2UNH5OPwEXRFjHjhPd0Q5L6SG760jrl856HiJLZV2Ur73sSB0vcZVhO84hxWHJvOksumEDQ7v32MuNMdJcd5EFeUYf/QaY6bP9EeBYn+07gFPzak8S0oTdJVlaH9ax43TSKlnGrZDVdaTNIZTlaGtVXz/nrNgwKposSskFCbcik9pVKVKnk0bKaShCiZsVzT6kufFxBVmcjh3VSYuwIouwxLK6jjTPK84oJe49cIRU0PqSoHcjjnDrNGu4k0bKaclbiXe0Ugjr9ElvfGBm1e4GE/YaW6ul9EVZYlleR9LnFTVKSXIPokaJQUouSrhVyYIvik4aKaclb4OtY5VCUSF/S+ZNz7xj521Fxln9msV5y7SGo0YpSazRMGEUpuTKFm5V9ctXYaRcVYow2DpWKWQ9BC1awAV1nDyTnnlXv2bxQsaxhvMQXlGjlCQCO2xhWFjemzKFW5398p1cRKgI11nHKoUiQ/6KIquOnmT1a96+3KBrWvv4c9zx4NbUiiJKiScR2EFCKioRWpnCrc5++U6db4H6J8SrNO04BE3a0ZNGvgT5zfN0dwRd07V3PxGauC0OYUo8icBOK6TKFG55l5zNm7INsLKodUK8qpOVlZa0A+XZ4ZJYEWkiX4LqSeSpSIOuKSpxW6skFdhphVRZwi3vkrOGfAhazpvlMt+OVQpZWGlJ3TV5+3GTjH6SRL4EFUGH/N0dUQVT3GQ9YilLYBdhqSctOVsHt1InEFT9MWh7Gjq6HOf8ma0V2UianybvHD1+xUWChHaSlaNO/iawFIJfwZK8CCuY4qXOrj+HtEVnkuaQmj8zWcnZTgn3rDp5l/uEDh4pZEHSSZ+8J4mSjH7ijir8FJmTF+euxXMzaXcYftc0Z9okVq7rr330id+IIMhwuOCWjYHPNe0I1G8kVIaL0BCfOdMm+abbnzMtu+SgRimEEDWMTzrpU8TkdlyXR9w5lbJj6cH/mmYdsm/lJ0PdeN8lr2Lzhvt6eX77UPNd8wr9LCOJOjncsw7c8eDWRNvTYJRCAHGsr6STPlXqcHFHFVWN0qpT9Infu+SOnnIYHBoOrMbnxS30s1TcSUabdYhSajdMSGqJxLG+kk76ZN3hWu2UcQRrlRRZXQlywfkxrBq7+I0jCLJW3HEXFJoopeIpwkgzSiGAOBo5zQPKqsMV1SnzjKWvq6WZtN1JrDhnFbT7+C/t3OWbQ995z8pQ3HVe/FZninjWRikEEEfg5/WA4nS4IjtlEleNn8B02uvdVkdLM40yThJWO6w66n57zwkj37MyFsFVYa6pEyniWRulEMCiE6ey6MYNDA27ill0yQiB38oDCrM243S4KnZKP4G56IYNIDTvoyNE926MqaWlmUYZ+xkP3vUeDn7lMeO8Z0XPsVR1rqkTyPtZ51mO82DgKmB/rPf/MlX9mogsAT4GONPln1fV2+zfnAucAQwDn1bV1Xm1LxbeXhO4J8YAACAASURBVOvTi9M8oChrM06HK6tThikzP4HprhDlMDg0XErKjCxIo4y9Qr1nfIMdQ8MMeupxh40yqzaxbuaa2pc8F6/tAs5R1SOA44CzROQI+7tLVHWG/c9RCEdgleCcDrwV+He7lGcpLFu9aZRAG9qtiRea+S0qilrEFmcRWpKFaq221/1d2MKqLAR61S3NtIuHnIWSlyyYwY6h3aMUwsTxjdwXAmZJ0OK3urTfEEye5TifAp6y/35BRB4Awt6Yk4HrVXUn8Khdq/lY4Jd5tTGMLNwzQSOCKCs5yF0AVmFzZ9spx/S2lCk0bnudNkW5TpL4znu6G+zctTtXS7OMlNtRBBXkGT9ubO0EatVGL4ZsKGROQUSmYNVrvgeYDXxSRD4ErMUaTTyPpTDudv1sCz5KRETOBM4EmDx5cm5tzsI9EyREg2LR3ceOmmzsHxhk5br+TK2zoPaes2IDEK0o/QRmY4yMmFOAPcWHnHPmMWFWVsrtKKo4F2QwuMldKYjIK4CVwNmq+kcR+RbwRSwP/ReBrwB/F/d4qnoZcBnArFmzMswNOJIsfKZBHd0vFl0IX6peRLRRWHvPvem+wBXcjjILG+GElT3NgzQpt+OOLFqxkM0EraHq5KoURKSBpRCuVdWbAFT1967vvwPcan/sBw52/fwge1spZBH6FVas5ujJ+/A/Dz/XFFAKrFzXz6xD9vU9RxEWZpj7Z3BomL3GjhmlzLyKMkhgZi38owR40pTbUEyIrJmgNVSd3CaaRUSAy4EHVPWrru0HuHb7W+C39t83A+8Vkb1E5FDgcOBXebUvDq1mUfWbDAbL8nYrBIewjKlFZEcMaq/DwOAQpxzTW/rkYpxMoknuy5MDg7lnsHUoe4I2aTZVQ+eR50hhNvBB4D4RWW9v+zzwPhGZgWW0PQb8PYCqbhSRFcD9WJFLZ6lq9Fr/jMhjUtL5/TkrNoyaQwjyewVZuEVYmGHtdch6HiMNcVxpSdYGHNjTXaivv8w6DVmMhuq6Et0Qj9xGCqr6C1UVVX29O/xUVT+oqkfa2+fZUUrOby5S1deo6lRV/VFebfOSNod9HObP7GV3grJIQRZuWgszTZ79r7znqMARQx7Wc1LiCvC9xu55vSeOb3DacZMDw3iLGImVTRajoTz7iqEamBXNxJ/ETWshBfnqk1YxS2phtpJnH+Ds5et9v09jPWdpXUZN1vqlhdgxtJtZh+wbmnK73X39WYyGTM6j8sl7pGaUAvE6SytDb99QzS5h7BhpLmKaOL7B+e+cnunDjdOBg14wZ11CFpEyWSfvi3KlhV130NxQGfmDiiaLyCcTUlsuRSTC7OhynA5xXAetDL29rp+J4xugjFjVusOzwjULojrweavuY+Hy9YGugKBSmEmrPGU9iRvlSksruFoNLKg6WayC7wQ3W5UpIiDCjBSIN4nbqoXkdv3MXrpmVLx/K0PwIGs/zDJc1dcfWOjFacf8mb2sffy5EftFhc76kYd1GeZKa/e1AGndB1mMhkxIbbmYIjsFEaezZClosnywYcPJsA68bPWmWBFQdzy4NVRxxCHLexcnNXe71HD2o1X3QauRT53gZqsylS6yIyLjVPXlzFpSMlGdJUsLKcsHG+U/d/bxduCFAZPI3nZkocBavXeOIugfGBwxOR+Umnvluv5ReaHmTJvEstWbWLh8fa0FWRUmek3Oo/KoTJEdEbkT+LCqPmZ/Phb4DnBUZi2pOFnWTsjCknULSj/cyfX82hgWEeVuRxYKrNV75+4E3lFLUGruOx7c2lSK7VQ60kz0djZFjNTijhQuBn4sIl/HSlL3NuAjmbWiZPLMeROUyK6VDKd+IZdeooR20OKu046bPKIdWVkmacJpw5ReFG4hWQXrOivafb7EEE3eI7VYSkFVV4vIx4GfAs8CM1X16dxaVSDnrbovNElaqwQJJLclm8Ux3cQR2nEtjjJ8yHGUXhRZu8CqQpSSNquNDa0S1330z8B7gL8GXg/cKSLnqOoP82xc3sSJwPHun7TD5SGQwn7bmzAaJe1+eQqfKKXnJig1d9YusKoQpqTbyU1mKI+47qNXAceq6iDwSxH5MfBdoNZKIW4EDqT3S+chkMKyrzrJ3aLa1Qp5C58ohelMNvfa8zO3bniKgUErxNdvEWC7hVEGKfN2cpMZyiPW4jVVPRtARKbanx9X1bfk2bAiCBM+7pQJs5eu4ezl61MtGsmjbGZY9tUi8tHkvYAmTGH29nRzyYIZPLb0JBadOJWV6/qbCgH8FwGWnZm0KNrFTWYyuZZLXPfRO4F/BcYBh9pZTv9FVefl2bi8cFwfQaMEJwInjm87zipZyNYn7z3mGJ9KbnlaiEmFT1JXU5Bl7xXkSSzjTgijbAc3mXGBlU9c99ESrHrJdwKo6noReXVObcqVKEHvjsCZvXRNpG87TofLQyC5FUNUWGrWJBE+aTp5XEUapZw6bdK1HdxkxgVWPnGVwpCqbrPq5jTJPllPAYRNYnonaaOEapkdLouw1LQkET5pO3kcRRqVxqPTLE6vodAlMsKtV4frbhcXWJ7kbezETYi3UUTeD3SJyOEi8m/A/4T9QEQOFpE7ROR+EdkoIp+xt+8rIj8Vkd/Z/0+0t4uIfF1EHhKR34jI0S1dWQBBL5fAqCRoUb7tMv3SWYSlQjr/bRIffZ6dPGy+pqhKalVj/sze5n1xXIp1qnlgEu6Fs6qvn0U3bhiRxHLRjRsyfbZxlcKngOnATuA64I/A2RG/2QWco6pHAMcBZ4nIEcBi4HZVPRy43f4M1oK4w+1/ZwLfSnAdsQl6ucaIjBKMQULn0gUzWs6i2epkWphQ7RLhlGOiLe1WCqbEzSiaZycPU06dbHHWWSHmEZjRTlxwy8YR4ddghWNfcMvGzM4Rd/HaduCf7H+xsCuqPWX//YKIPIC1Gvpk4M32bldizVN8zt5+laoqcLeI9IjIAe7KbFng5/oARllVkN/CrSxcG0GuE+da4mQyLcJ/m7Wf22/o7LcIMO8kfFV2xdRZIZqEe+F4sytHbU9DqFIQkVsILidM3OgjEZkCzATuAfZ3Cfqngf3tv3uBza6fbbG3jVAKInIm1kiCyZMnxzn9CMqO3HHO3aowDlJuSY4XJCT6BwaZvXRNpnWqs+jkSZRpVsqojnMTdY9C6oRIsSoTNVL4V/v/dwF/Blxjf34f8Ps4JxCRVwArgbNV9Y/uyWpVVRGJX8DY+s1lwGUAs2bNSvRbB/dLd+hi//V3Tw4M5iYQsrDk4kQfReUNChttZCn8surkSUNQnd/EUUZBo4E6RsO0QxSSwZ+e7saIdTnu7VkRqhRU9WcAIvIVVZ3l+uoWEVkbdXARaWAphGtV9SZ78+8dt5CIHAA8Y2/vBw52/fwge1uuhFlVeQmErCw5R9jOXromMOPpqr7+wLbGGW2cvXw9Zy9fT093gyXzsi0XmpSkyjSuMgpT/nV0xRgXTPuyZN50Ft2wYUR24MYYYcm86ZmdI+5E8wT3ugQRORSYEPYDsYYElwMPqOpXXV/dDJxu/3068APX9g/ZUUjHAduynk/wI2xiKy+BkPVk2qITpyI+2xVCJxfdE7VRDAwOseiGbKMckpLXpHWQ8j97+XrGiN+drb4rJm4gQCdS5xXT82f2suzUo0YEVyw79ahSUmcvxEqC9wiWAXoI8PcRv5kNfBC4T0Scii6fB5YCK0TkDOBxrER7ALcBbwceArZTUGruMKsqq8L1Sc4ZF6+7I24OJ7+2hI023Azt1lLcJkFFdiAbt0jYPfLON2V1TkM51HGOyEtVUmf/WEQOB6bZmx5U1Z0Rv/kF+BqwAMf77K/AWXHakzVBNzmo5kDSwvVJzhkHvxfbKywd4iqwKFeSQ9FuE78iO+6EeGnmCbyEza04dImwW9W4YmpOHeeIiiZJOc5jgCn2b44SEVT1qlxaVRHmz8ymcH3W+L3YbmHpkMSijTNxDcW7TYKutbenO7QeRauRSl52q/Lo0pNC2+pXYS9tISVDPtRxjqhoYs0piMjVWJFIbwL+wv43K/RHbUJY4fqyCHqBHWGZNhOo44e+dMEMGl2jB3mNMVKY28Tx+6bN65RkAVecuZUoZei3EPCau59ItTDQkB9lrZiu0zxG3JHCLOAI28XTUSSxLIpa5BTk7oiynuPitPmCWzY2F8UUGX2URV6ntJFKfueOM+KKUxjIuCnKp4xw3brNY8RVCr/FWqeQezRQ1QgSwE5aDEf4A4U9+CJe7DIXEGWR1ynoufWMbzB76ZpAxZ02CCCu+8G4KcqljHDdus1jxFUK+wH3i8ivsPIfAfFXNNcFP0s/blqMvRtjIh98ViOJdo9Dz6LcqN9za3QJL+7Y1Rz9BCnuNAoxzmS1s5+hXIo2eOo2j5GknkJb4zfEW3TjBiaMG8vg0DBddjqMroC0GEGWrTu3v/f4C5evZ+3jz3Hh/CMTt7edUwFk4R7zU5wv7dw1ajVoVhZbnMlqE8ramdQt7UjckNSf5d2QsvEb4g0Na1OIDKsi+Meth+E8+KAommvufoJbNzxV+mrhKpGVe8yrOMNSmrSKc55zVmzwfUe6RNqyBKghmrqlHYlKiPcLVX2TiLzAyGhHwVpa8Ce5tq5A4giGMHXQ091g567dgQ8+7PgDg0Ox5x/cLqie8Q1UYdvgUFu5kPJyj+VtsTnti1NKNAvqlr21U6mbuzcq99Gb7P9fWUxzyiOuTxj81wM4uUeCHnzU8eO4MbwuKHe63KpHNCQlD/dYGostqeAtSgDULaKl00nzPpel9KXOUaazZs3StWsj8/LFIk4YpJvenu5ED2tVXz8Ll68PHW0IhC6QipOKIquw1DoSpxMl6WhOlSt3UZNGl7Ds3dnmmklD0LvQyc+/nQgKjc5qxCki6zxJTpskWdHc1ngtvJ7xjcDCFWk6nt/qaC9pY+/dZFkLoU7EtZyTWGxhVa7Kvrd1i2gxJKPMMFajFFx4BcZ5q+4bJcRbmSC6cP6RzDpk3xGLwpIcN0xRuQkSiFkNR6voy86jExVR5SotdYtoMSSjTKUfN3V2R3Lh/CO5ZMGM2Kkj4ixlnz+zl74vnMClCY7rkMTT503p0Eo9ZjdZHSdrOs1yLquWcZ3SNdSZstJxgBkpROJ1KzmC1s9XnWTiL83E0zafikthuAViVpZ0VVdn5mE5F1HlKi1lRLSYye3iKDOM1SgFH9zukX26G7z08q6mbzmoI+QhLL1umrjuIwe3QMzKkq6qRZ5HJyqiylUrFL2AsaoGQTtSZhhrbkpBRL4HvAN4RlVfZ29bAnwM2Grv9nlVvc3+7lzgDGAY+LSqrs6rbX4EFXLxsxT9OkLWwtLPKmuMERpdMmry0w+vQMzKkq6qL7vVThQ2T1K1+ZOyqKpB0K6UlbUgz5HCFcA3AG/NhUtU9V/dG0TkCOC9wHTgQOC/ROS1qhovPrRF/Aq5ROHtCFkLS98V1ruV8Y0xoUpB7HN6hVeUJR138rjKqzPTdqIot0inKgEvVTUIDNmSm1JQ1Z+LyJSYu58MXG9Xc3tURB4CjgV+mVPzRhAn7bEXb0dIKiyjhHCQ9bV9aHdgm8JCZcOs3iS+4na0notwi1QxYispVTYIDNlRxpzCJ0XkQ8Ba4BxVfR7oBe527bPF3jYKETkTOBNg8uTJmTQo6fDXryMkEZZxhHCSFdZBbfISZPUmFYpVsJ6zFLJ5u0XaZYLWr87GXmNNAGO7UbRS+BbwRSwPzReBrwB/l+QAqnoZcBlYK5qzaFSUAG6MEV6x91gGtofnGIorLOMI4bg1kx1aWemYViiWZf3GEbJJ2pa3W6TdJmh3uEarSfJ2GepBoUpBVX/v/C0i3wFutT/2Awe7dj3I3lYIfgI4bnH4NAQJW2c1siPITjmmd0SNX7/Uz9htbKV9aYRimdZvlJBN2rYs3SJ+yqidJmjbTcEZRlPo2E9EDnB9/Fusim4ANwPvFZG9RORQ4HDgV0W1a/7MPTV6ncVkpx03uZnfaNnqTZku0gkStgIjFoWtXNfPohOn8ujSk7hr8VyWzJuey4KlNAuhktRAzpooIZu0be7nD1aaa2f/JM89aGFfz3j/dQ11nKBtJwVn8CfPkNTrgDcD+4nIFuB84M0iMgPLCH8M+HsAVd0oIiuA+4FdwFlFRR45uF0/eVnBQWGvMDrzKoy2wPKa5E1z3DKFQ9TIJk3b/NJeJ33uQcpIUN/MunWcoDURSO1PntFH7/PZfHnI/hcBF+XVniTEcU8kFcxhYa+9IXMaXkEWNm/Rio8/6eRxmcIhyt2Ttm2tukbiRowJcMox5U/Wp8FEILU/JnTAhzBL089FsHD5eqZE5IIJCnsVrI7WGyCw4grZonMSlZV7B/zdfe6J9rRta3X0E/dZKXDHg1sj98uTtDmMou69of6YegqMtrC3v7zLN52EI7ijQkV7uhujymseuviHgYvinMnsVvKnl5Ffv8qx92na1uo9TFKTI6p2Rp7knavfUH1MPYUQ4qaTcCzNhcvXRx7TCdNb+/hzzeihMSKB9Z2fHBhseb6gDB9/FdYrBJGmba26RvyeYVDEWJk++KpEEFXZqOhkOl4pBKWT6OluMGGvsaNeWGeiOIrBoeERtRiCFALsERCtCFkzAdg6aRSzn2BzjyqCrPI50yaNCD8uUiBWIYKoXRb0tSMdrxSCOsK2wSHWn3/CqO1JFpXFccxl5YfvlAnArK3LKKEe9dsoweanaOZMm8TKdf2lCcQqGBBVGa0YRtPxSiFpB3F3cr/Q0jgkre8ch7hWbp2H7Flbl60eL65g844AZy9dU6pArIIBUYXRSl3Juw93vFJI00G8axr8ymsGKYs8J36j3E91GLJHpbDOUpjmFYIaJdjKFohp56+yFEZVGK3UkSL6cMcrhVYneB1B7O0wXhcBlO/OiVrpm1WHTys8ol74rIVpFiGoaQRbFQRi0vmrrIVRFUYrdaQIt1vHKwVobYLXKwAvWTCjeaxZh+xbqYySYTmXsurwrQiPqBc+a2Ha6vHSCrY6CsSshVE7pmAvgiJGmUYptEAcAZh1RslWhvBBQtDJ9eMmbYdvRXhEvfBZFQpyyCMENc7zqKNAzEMYVTmkuaoUMco0SqEFogRg1tZVq0P4ICEYFEmVpsO3IjyiXvgwYZrm3mQhnNMKtroJxCq4vPyoc+BEEGHXVMQo0yiFFogSgFlbV60qmSAhGLT2ImmHX9XXH7hIL86x4rzwQcI07b1JI5zbURBFUUWXVx0CJ5IStzSsiT6qIHEEYNbWVdicwKq+/tiKwW+/Vju88zL73Y+4x2rlhS8qoqcdBVEcqujyase1DnGuKe9RplEKKYgrALO2rsIqxLUimObP7GXt489x3T2bGValSyRxFs+ghH9dIoly6sR94b3Wes/4hm++qqzdG+0oiOJSNZdX2aG9eVCFazJZUlMQJQDBWqC0cPl69ho7honjG5lklJwzbRIS8J07tDRpBsxVff2sXNffVHLDqqxc158ow2rQS7tbNXNB4pcR9sUdu2h0jbw7ebg3qtBpDRZBCr/seY5WqMI15aYUROR7IvKMiPzWtW1fEfmpiPzO/n+ivV1E5Osi8pCI/EZEjs6rXVkQJgCBEQJrYHCIHUO7uWTBDO5aPLelqKOV6/pDV08HpfaOSqGdRRW1JC9z2rTNYe0d2q1MGDc295TOVei0dafV5+9QZvr2vKjCNeU5UrgCeKtn22LgdlU9HLjd/gzwNqwSnIcDZwLfyrFdLRMmGFoVsEEdJmh0ksX5s7B+477McZVWmOAIy1d11+K5zfKlebg6qtBp60yWdT/mz2y/2g5VuKY8K6/9XESmeDafjFWiE+BK4E7gc/b2q9Qq7nC3iPSIyAGq+lRe7YsibVhYUGrtOAI2bBIz6vetnD+LCfG4E5FBSuucFRuax4mazC0zPLKKE651Io9FcO1278u+pqInmvd3Cfqngf3tv3uBza79ttjbRikFETkTazTB5MmTc2lkK2FhrYR3hnWYsEnm3hbPn9WEeJyXOUg5Das273GU4MiivUWWLjXsIYtRaSeGBBdJadFHqqoikrjsm6peBlwGVuW1zBtGsFA6e/l6lq3e1HwJ/V7EVgRWWIe5ZMGMWNWy0ib4g2Ks3zDl5gj+KMHRans7Nay0CrQ6yjPPrv2ypP7ecQuJyAHAM/b2fuBg134H2dtKIcxqiXoJWxFYYR0m7nFbSb1QRKeKqkfhtDlKcCRpr1+51U4IK62iRd3qKK+TQ4KhPbOk3gycDiy1//+Ba/snReR64A3AtjLnE8KsWYh+CcMEVitL2OMKwjj7lSUwnHOcs2JD4MK/LNd3+HWiINoprLSqFnWro7xODwmudZZUEbkOa1J5PxHZApyPpQxWiMgZwOPAe+zdbwPeDjwEbAc+kle74hCnupr7JYwrYP066sLl6zl7+frmvMDF7zoyd2FdtsBwzhEk+LN0Z8WJ2nJop7DSKlvUrYxKq5qDqShqnSVVVd8X8NXxPvsqcFZebUmKWygFWZbOS5hEwPp1VMdWdn538buOzK0IT1g78hAYYcoySvBn5c6K21naLay0XS3qKuZgKhKTJbVEHKEUVHjdeQmTCNioDlmUJVeEwIhbvziPUVCc9BfuyngTxzc4/53TS7egs6RdLepODwk2WVJzJo7bJ+oljCtgwxLohf0uD4oQGGW4L/wUUWOM0OgShoZH3nf3J3fNi3ahnS3qTg4JNllScySJ2yfsJYwjYMMS6IX9Lg5pJoyLEBhluC+C0l/0dDeYsNdYnhwY9FXMZfna85zs73SLup0xWVJzIitLdtGJU1l044YRlmijS0YI2LiTnWnTVSedMC5CYAQpyzEiHLr4h7mcMyz9xfrzTwDg0MU/TPTbvChisr+TLWpDejpWKQRNIKcSDt4BgOdznGOm8Wu3otjyFhhBEVyOlZ6HEIwzaquKr73K0UGGzqYjU2ev6usPTEHdM76R6FjLVm9iaPdILTC0W0ckoAsTOL093Vy6YAZ9XzghsTCoQoRJUOI6b2KvLhl9x5NmYo1izrRJkdurktCuCs/OYPCjI0cKy1ZvCkxB/eKOXbGrmEG8zh3kw281+2HZVm+cHFHO9YW5bbLyrd/x4NbI7VXwtbdattRgyJOOVAph1phj5ccVEkEhj4pVaCfrxVhuyo4wSeICCVJgPeMbsXzrcRRHXOu7TF97FmVLDYY86UilEJXGIskQPiygKCi7alb4KZs50yaxbPUmFi5f7ys8s4x4SeICCVJgqkQqlriTsmWPnOKQVdlSgyEvOnJOwc+v7MYbThpWJWrb4OhRgpus/eZe5s/sbRaWWXTiVFau6w8sYJJlgRNIVoXMO8fgFA8Jun+OYlnV1885KzbEKhxUlfmCMIosW2owpKEjRwpO57vglo2jXD9uIRLHQo0adUA+k4d+Fn+UOyfriJek7iu/0VJY/Yeo9R1++acGh4bpsv31vSXMF0RRh9GMobPpyJECWAKq7wsncOmCGYGl7+KUtowadcAeAZdFXVoItvijwmyzjngJsv6TrvMIsu6j1nd480851z+sOiq5XlWow2jGUG2ylCV+dORIwU2Yrz+OEPUmz3Pn1AGrw8+ZNinThUpByqorIqIlCyvVb4TSSgK/sEn4oNKikD7/VNlUIfrJUF/asZ5CrQiKLPKuZfAqBq/7ImuhFVbSsrvRFejOaTVaKa8XMkgxBykx76RsmTH/aSbuzUpjQ1qKMIA61n0Uh6DIop2ehxLlvshaaAVZ9o77JsidE+buiTMkjeNOy5IgV8tX3nPUqKgjP/L202c9cW8wRFHregp1Z1VfPwMBkTHbh3aPWOAWpb2zmlx0rNIgN1VY7WgHv+/jjgCKtsjjulrKWq9RJ7eVoT1o23oKIvIY8AIwDOxS1Vkisi+wHJgCPAa8R1WfL6N9jpAMw93xo4RlFkLLK7iVPTUBvFE2SV0acYVbGZEzcVwtZfnpi1KSVay1bCiHdq+nMEdVn3V9XgzcrqpLRWSx/flzZTQsTlZTd8cPmntwhGUWQiuoaltvT/eIid5Vff0jsrb2Dwyy6MYNI9oRdi1h28teQR1GGX76IpRk2aVTDdWi0+opnIxV0xngSuBOSlIKcSw9dzjkizt2jfremz67VaEVV3BfcMvGUQVlhoaVC27Z2FJNCLCuYe3jz3HdPZsZVqVLhFOO6dxJ0yKUZNEuKjMqqT55G0BlTTQr8BMRWSciZ9rb9lfVp+y/nwb29/uhiJwpImtFZO3Wrf4J0FolytLzhkN6s6QCTBg3NvP6BHG2+41Y3Nv9JpTjxs6v6utn5br+ZtjrsCor1/V37MRqFus0oihyHsdMnBugPKXwJlU9GngbcJaI/LX7S1VVRlcpcL67TFVnqeqsSZP8UyW3yqITp9Lo8k+uPXF8I1Y4ZFT6izRtanXRU1CnBzjlmN5meuugEUDR0Ud1wJ1m5K7FczO34IqMrDLPNx55Lx4rm1KUgqr22/8/A3wfOBb4vYgcAGD//0wZbQOro08Y5+9ZG+8ZARTVad1WKViC2+mw7peyp9u/HkRPdyOw019wy8ZYI4C8rNZ272StUOQKaFPjIZpOGE0VrhREZIKIvNL5GzgB+C1wM3C6vdvpwA+KbpubqERtDll32jABOX9mb/N83gpmzn5L5k2nMWbkKKcxRlgyb3pg535++1AsCzGoAFErCrATOlkrFOGicihrvUed6ITRVBkTzfsD3xfLVTEW+E9V/bGI3AusEJEzgMeB95TQtiZJIkv2Gjum+aKkKavpECfSJGriMSw6ISj5XBDehHNxJtST0spEaqdMihYVWVXl6LKq0AmjqcKVgqo+Ahzls/0PwPFFtyeIOB3EK8QBdgztTn3OOAIybj4mPyESVDc5CLcCzGtCPW0nM6Ga2VP0eo86KvUqZLnN+75VKSS1UsTpIEXlNHJvb+Wl9OZoCqPRJby0cxeHLv5haHrwClxjBQAADR9JREFUVifU016PWU2cjLiCpKhRSV2VetmjqSLum8l9FEJUZEmQEO8fGEw1aRrHp9vqHIZzTb0hQnfi+AYoDAwONf38/rFYrVtIaa+n1WF8J01uV3Hepq6++SLnePwo4r6ZkUILhFnQ3pBPyCaHT1ZD/KBzXfyuI60FcB5XkTutRlDb0pD2eloZMdXVSk1LFUdVdfbNl5nl1iTEqyDuYfg+3Q0aXTJqBbEbJ+Rzx9DuSCEUV0Bm8VIGnQuCF8A5aTWy9mWmuZ5WhvFVFJJ5UoQgSernroJvvo60bUK8uuK1MAcGh2iMESaObzCwfch/tR3+QjZICBVphfida/bSNYH7e/MsJSHrybEkIwzvuaMq1LUbeQuSNCOvsn3zdaXdE+JVijhCy8/CHNqtjB83lr4vnMDspWtSh3xWhbA2tbL2osjiPFHn9rrBHNrVSp0zbRLX3v1E5q4/hzQjr7Iy29adTkuIVxpZ1RMI0uJ7jR3jW5uhikIoyKrs6W6kfvHKdNcEZZfNY36kCniNmznTJrFyXf+IaxXILJHhqr7+1COvMn3zdaZdE+JVirgz+lHRQUGRCUvmTS+8WHva6JqgaKAl86anbkuZk4pB53DmR8qIIMkLvyija+9+wlcp3vFgeDLJOO9PVN2RKho9hmjMSIFs6wmEafGoIV9WfvdW3DV5DE8DRx8BaTOyJOjcrcyPVJWgUZEfYQo57vsTVnekXUZenYhRCiSrJwDpBGbUkC9Lv3ur7pqsh6eLTpw6ovCPw4s7do0oa5oHWU3M1WH1bZKRV5gVH/f9CTtfO4y8qkre76JxH5FsAVVeqZKzXJRStRjwoKyzQ7s198VKcbPLhuHnllm4fD3nrQov2Vo0QYLeu/AwSinGfX+Cztfb020UQk4UsRDRKAXKX6UI2QryKma7jJt1Nkscv/jC5et5aecuusbIiOyyi27cEKszBbllrr37iUqthA4ybk47bnKidzvu+1NkWm+DhVnRXCB5zOgnGeaFubCSDherGANe9GIlvzUlXqLKlDqETVZXacFb3qvdve9P2vPVwRVXVcyK5hqTdI4gqCPOmTYp8VxDFWPA/a5PsK5n9tI1I9qXhdAImwR1E7R6202dFrzludo9iwR6nZZiJGvMiuaScQunnvENVC03SBxBlXSyN6gjpp00rloMuDdDq3udgDdHVBZCI0thvejEqSxcvr6jFrzl9f50WoqRrOnIFc0i8lbga0AX8F1VXVpGO7wWjduijCOo0gzz/DriwuXrEx8nDUUM6Z3r81v57faLZiE0wqx7N0HlS73tXvv4c7muCu4UqhYEUTc6bkWziHQB3wTeAmwB7hWRm1X1/qLbEuV+iBJUWQ3zihguFj2kTyMYkgqNOAWFnDKlcbhw/pHMOmTfSrnk6ohJhNc6nbai+VjgIVV9RFVfBq4HTi6jIXGEUFSeoCwiM4qI8Cg6t31YdEtWkVN+EWUf8EThLDv1qESdK69w5E7CRCxVn0qNFIBeYLPr8xbgDe4dRORM4EyAyZMn59aQOO6HMEGV1TCviOFi0UP6KL9oVj7Tqs2rGKoZBGEYSdWUQiSqehlwGcCsWbOCCxm0SJT7IY6gykoo5S3cih7SxxEMRmi0L0ZZV5uqKYV+4GDX54PsbYXjFVxJo4/qRBnrGsIEgxEaBkN5VE0p3AscLiKHYimD9wLvL6sxnSKczJDeYDA4VEopqOouEfkksBorJPV7qrqx5GZ1BJ2iAA0GQziVUgoAqnobcFvZ7TAYDIZOpGohqQaDwWAoEaMUDAaDwdDEKAWDwWAwNDFKwWAwGAxNRDW39V+5IyJbgZeAZ8tuSwD7Ud22QbXbV+W2gWlfK1S5bVDt9mXVtkNUdZLfF7VWCgAislZVZ5XdDj+q3Daodvuq3DYw7WuFKrcNqt2+Itpm3EcGg8FgaGKUgsFgMBiatINSuKzsBoRQ5bZBtdtX5baBaV8rVLltUO325d622s8pGAwGgyE72mGkYDAYDIaMMErBYDAYDE1qqxRE5K0isklEHhKRxWW3x42IHCwid4jI/SKyUUQ+U3abvIhIl4j0icitZbfFi4j0iMiNIvKgiDwgIn9ZdpvciMhC+7n+VkSuE5G9S2zL90TkGRH5rWvbviLyUxH5nf3/xIq1b5n9bH8jIt8XkZ4qtc/13TkioiKyX5XaJiKfsu/fRhH5ctbnraVSEJEu4JvA24AjgPeJyBHltmoEu4BzVPUI4DjgrIq1D+AzwANlNyKArwE/VtVpwFFUqJ0i0gt8Gpilqq/DSvH+3hKbdAXwVs+2xcDtqno4cLv9uSyuYHT7fgq8TlVfD/wvcG7RjXJxBaPbh4gcDJwAPFF0g1xcgadtIjIHq279Uao6HfjXrE9aS6UAHAs8pKqPqOrLwPVYN6oSqOpTqvpr++8XsIRaZYoViMhBwEnAd8tuixcR2Qf4a+ByAFV9WVUHym3VKMYC3SIyFhgPPFlWQ1T158Bzns0nA1faf18JzC+0US782qeqP1HVXfbHu7EqLJZCwP0DuAT4R6C0SJyAtn0CWKqqO+19nsn6vHVVCr3AZtfnLVRI6LoRkSnATOCeclsygkuxXvjdZTfEh0OBrcB/2O6t74rIhLIb5aCq/VjW2RPAU8A2Vf1Jua0axf6q+pT999PA/mU2JoK/A35UdiPciMjJQL+qbii7LT68FvgrEblHRH4mIn+R9QnqqhRqgYi8AlgJnK2qfyy7PQAi8g7gGVVdV3ZbAhgLHA18S1VnYuW2qsycke2fPxlLeR0ITBCRD5TbqmDUijmvZNy5iPwTlqv12rLb4iAi44HPA18ouy0BjAX2xXJLLwJWiIhkeYK6KoV+4GDX54PsbZVBRBpYCuFaVb2p7Pa4mA3ME5HHsNxuc0XkmnKbNIItwBZVdUZWN2Ipiarwf4BHVXWrqg4BNwFvLLlNXn4vIgcA2P9n7mJoFRH5MPAO4DSt1mKp12Ap/A12HzkI+LWI/FmprdrDFuAmtfgV1mg/04nwuiqFe4HDReRQERmHNdF3c8ltamJr7suBB1T1q2W3x42qnquqB6nqFKz7tkZVK2PpqurTwGYRmWpvOh64v8QmeXkCOE5ExtvP+XgqNBFuczNwuv336cAPSmzLKETkrVjuy3mqur3s9rhR1ftU9U9VdYrdR7YAR9vvZRVYBcwBEJHXAuPIOKNrLZWCPUn1SWA1Vodcoaoby23VCGYDH8Sywtfb/95edqNqxKeAa0XkN8AM4P+W3J4m9gjmRuDXwH1Yfai0tAgich3wS2CqiGwRkTOApcBbROR3WCObpRVr3zeAVwI/tfvGtyvWvkoQ0LbvAa+2w1SvB07PeqRl0lwYDAaDoUktRwoGg8FgyAejFAwGg8HQxCgFg8FgMDQxSsFgMBgMTYxSMBgMBkMToxQMhpIQkfkVTJRo6HCMUjB0JHYyu7KZj5XldxQVaZ+hAzFKwdCWiMiH7Hz9G0TkanvbFSLybRG5B/iyiMwQkbtdef0n2vt92q6F8RsRud7e9jeuhYh9IvJKn3N+QER+Ze/z/9sp3hGRF0XkIrstd4vI/iLyRmAesMze/zUicqeIXCoia4HPiMjx9rnus3Pr72Uf7zER+bK9/VcicpiIvFJEHrXTqyAif+L+bDDExSgFQ9shItOB84C5qnoUVu0Ih4OAN6rqZ4GrgM/Zef3vA86391kMzLS3f9ze9g/AWao6A/grYNBzzj8HFgCz7X2GgdPsrycAd9tt+TnwMVX9H6x0FItUdYaqPmzvO05VZ2HVC7kCWKCqR2IlQvuE65Tb7O3fAC61U7TfiZUSHawUJjfZ+ZkMhtgYpWBoR+YCN6jqswCq6s5Jf4OqDtt1G3pU9Wf29iux6jgA/AYrzcYHsLJ4AtwFfFVEPm3/bhcjOR44BrhXRNbbn19tf/cy4FS4WwdMCWn7cvv/qViJ9/7Xp30A17n+dyrTfRf4iP33R4D/CDmPweCLUQqGTuOlGPuchGWpH40l5Meq6lLgo0A3cJeITPP8RoArbat/hqpOVdUl9ndDrvw0w1hWfyvtg5HpsBVAVe8CpojIm4EuVR1VYtJgiMIoBUM7sgY4VUReBVbNYu8OqroNeF5E/sre9EHgZyIyBjhYVe8APgfsA7xCRF5jZ9D8ElaWXq9SuB14t4j8qXNOETkkop0vYCWG82MTloA/zN0+1/cLXP//0rX9KuA/MaMEQ0pMhIOh7VDVjSJyEZaQHwb6gA/77Ho68G27sMojWC6XLuAa270kwNdVdUBEvihWfdzdwEY81cJU9X4ROQ/4ia1YhoCzgMdDmno98B3bJfVuz/F2iMhHgBvsSKR7AXc20Yl2FtmdwPtc268FLmSPe8lgSITJkmow1Ay7+MssZ87E8927gZNV9YOFN8zQFpiRgsHQJojIvwFvA0ztDkNqzEjBYDAYDE3MRLPBYDAYmhilYDAYDIYmRikYDAaDoYlRCgaDwWBoYpSCwWAwGJr8P10h3/JT2hmRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "tbtbh25Y-Zy4",
        "outputId": "c712327a-c6f0-486e-d49a-a0ed8def0d9c"
      },
      "source": [
        "Y = []\n",
        "for i in range(len(collect_Cce)) :\n",
        "  Y.append(1)\n",
        "y = []\n",
        "for i in range(len(missclassification_Cce)) :\n",
        "  y.append(0)\n",
        "\n",
        "values = [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10, 11, 12 ,13, 14, 15, 16]\n",
        "\n",
        "plt.plot(collect_Cce, Y, 'b^', missclassification_Cce, y, 'r^')\n",
        "plt.title('Cross entropy')\n",
        "plt.ylabel('Type')\n",
        "plt.xlabel('cross entropy')\n",
        "plt.legend(['Collect', 'Miss'])\n",
        "plt.yticks([1,0])\n",
        "plt.xticks(values)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yOIVHOpYL_Z",
        "outputId": "9f85ddb2-a20b-4d6e-8fdb-e8cdfd276d63"
      },
      "source": [
        "print(max(collect_Cce))\n",
        "print(min(missclassification_Cce))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1666403\n",
            "0.7434929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8E1WLvmhpz4",
        "outputId": "13de610f-97d1-451e-a0ed-d5c5f1f5217b"
      },
      "source": [
        "section = []\n",
        "section_rate = []\n",
        "max_m = round(max(missclassification_Cce))\n",
        "\n",
        "for i in range(max_m+1) :\n",
        "  section.append(0)\n",
        "\n",
        "for m in missclassification_Cce :\n",
        "  section[round(m)] = section[round(m)] + 1\n",
        "\n",
        "  \n",
        "for i in range(max_m+1):\n",
        "    section_rate.append(section[i]/len(missclassification_Cce))\n",
        "\n",
        "print(section)\n",
        "print(section_rate)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 47, 57, 45, 36, 30, 31, 32, 26, 23, 21, 18, 9, 6, 4, 3, 21]\n",
            "[0.0, 0.11491442542787286, 0.1393643031784841, 0.1100244498777506, 0.08801955990220049, 0.07334963325183375, 0.07579462102689487, 0.07823960880195599, 0.06356968215158924, 0.05623471882640587, 0.05134474327628362, 0.044009779951100246, 0.022004889975550123, 0.014669926650366748, 0.009779951100244499, 0.007334963325183374, 0.05134474327628362]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2urcrdC3bn3J"
      },
      "source": [
        "def static_Threshold() :\n",
        "  threshold = []\n",
        "  for i in range(1, 10):\n",
        "    threshold.append(round(i * 0.1, 1))\n",
        "  return threshold"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUdZfL9CcsW9",
        "outputId": "0d97a7d4-43a0-4400-9887-5cc85c7e1a2c"
      },
      "source": [
        "staticThreshold = static_Threshold()\n",
        "print(staticThreshold)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GuX1afKcWzk"
      },
      "source": [
        "def dynamic_Threshold(missclassification_Cce, cce) :\n",
        "  #Z = [1.96, 2.17, 2.576] # 95%, 97%, 99% two-tails\n",
        "  Z = [1.645, 1.96, 2.326] # 95%, 97.5%, 99% one-tails\n",
        "  threshold = [min(missclassification_Cce)]\n",
        "  x_ = np.mean(cce)\n",
        "  o = np.std(missclassification_Cce)\n",
        "  n_ = (len(missclassification_Cce))**0.5\n",
        "\n",
        "  for z in Z :\n",
        "    threshold.append(x_- (z * o)/n_)\n",
        "  \n",
        "  return threshold"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9dMgr3ehAMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0362f23f-d698-4df1-9d62-2325dcced307"
      },
      "source": [
        "dynamicThreshold = dynamic_Threshold(missclassification_Cce, cce)\n",
        "print(dynamicThreshold)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7434929, 1.04800775514659, 0.9837800629025942, 0.9091536014381421]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6HhUB1vhVK_"
      },
      "source": [
        "def detection(threshold, cce, collect) : \n",
        "  PMD = []\n",
        "  for i in collect :\n",
        "    if cce[i] > threshold :\n",
        "        PMD.append(i)\n",
        "  return PMD"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9uUzEC1h4na"
      },
      "source": [
        "def detection_PMD(list_of_threshold, cce, collect):\n",
        "  PMD_by_threshold = []\n",
        "\n",
        "  for th in list_of_threshold :\n",
        "    PMD_by_threshold.append(detection(th, cce, collect))\n",
        "  return PMD_by_threshold"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsVPum8jkUL_"
      },
      "source": [
        "PMD_By_Static_Threshold  = detection_PMD(staticThreshold, cce, collect_Idx)\n",
        "PMD_By_Dynamic_Threshold = detection_PMD(dynamicThreshold, cce, collect_Idx)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y36FANL0kxIC",
        "outputId": "ce810e92-9e70-4179-8d01-8e584bfd4ffe"
      },
      "source": [
        "print(len(PMD_By_Static_Threshold))\n",
        "print(PMD_By_Static_Threshold)\n",
        "print(len(PMD_By_Dynamic_Threshold))\n",
        "print(PMD_By_Dynamic_Threshold)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[8, 12, 21, 32, 51, 60, 64, 65, 76, 94, 97, 106, 109, 123, 131, 137, 156, 192, 197, 221, 254, 263, 279, 280, 291, 292, 302, 304, 313, 324, 336, 352, 377, 401, 437, 446, 456, 458, 465, 485, 509, 511, 520, 522, 556, 584, 590, 594, 597, 610, 630, 631, 655, 662, 680, 694, 695, 700, 701, 719, 724, 725, 730, 762, 781, 790, 807, 810, 831, 840, 847, 849, 851, 869, 880, 891, 902, 903, 916, 918, 921, 928, 940, 941, 955, 957, 977, 989, 994, 995, 996, 998, 1000, 1026, 1032, 1052, 1072, 1091, 1150, 1151, 1155, 1168, 1182, 1206, 1209, 1220, 1224, 1226, 1232, 1233, 1237, 1242, 1253, 1255, 1256, 1257, 1269, 1272, 1308, 1363, 1375, 1413, 1417, 1437, 1438, 1445, 1466, 1474, 1508, 1513, 1524, 1525, 1528, 1559, 1573, 1580, 1582, 1600, 1606, 1609, 1619, 1624, 1629, 1632, 1635, 1654, 1660, 1664, 1694, 1695, 1712, 1713, 1714, 1716, 1725, 1735, 1759, 1778, 1789, 1796, 1797, 1799, 1803, 1804, 1826, 1828], [21, 32, 51, 60, 65, 76, 94, 123, 131, 156, 192, 197, 254, 291, 292, 302, 313, 324, 352, 377, 401, 446, 465, 520, 556, 584, 590, 594, 597, 610, 630, 631, 655, 680, 694, 695, 701, 719, 724, 725, 730, 762, 781, 831, 840, 847, 849, 851, 869, 880, 891, 902, 916, 918, 921, 928, 940, 977, 989, 996, 1026, 1032, 1052, 1072, 1091, 1150, 1151, 1155, 1168, 1182, 1206, 1209, 1220, 1224, 1226, 1232, 1233, 1237, 1242, 1253, 1256, 1269, 1272, 1308, 1363, 1417, 1437, 1438, 1466, 1508, 1513, 1524, 1528, 1559, 1600, 1606, 1619, 1624, 1629, 1654, 1664, 1694, 1695, 1716, 1725, 1759, 1778, 1789, 1796, 1803, 1804], [32, 51, 65, 123, 131, 156, 192, 197, 254, 291, 292, 313, 324, 377, 401, 446, 465, 520, 584, 590, 594, 597, 610, 630, 631, 655, 694, 695, 701, 719, 724, 725, 730, 762, 840, 849, 851, 869, 891, 928, 940, 977, 989, 996, 1032, 1052, 1072, 1091, 1150, 1151, 1155, 1168, 1182, 1206, 1209, 1220, 1226, 1233, 1237, 1242, 1253, 1256, 1269, 1308, 1363, 1417, 1438, 1466, 1513, 1524, 1528, 1559, 1600, 1606, 1624, 1629, 1654, 1664, 1694, 1716, 1725, 1778, 1789, 1796, 1803, 1804], [32, 51, 123, 156, 192, 197, 254, 291, 292, 313, 324, 377, 401, 446, 465, 584, 590, 597, 630, 631, 694, 695, 701, 719, 724, 725, 762, 840, 849, 851, 869, 891, 928, 940, 977, 989, 996, 1052, 1072, 1091, 1150, 1151, 1155, 1168, 1182, 1206, 1209, 1220, 1226, 1237, 1242, 1308, 1363, 1417, 1438, 1524, 1528, 1559, 1606, 1624, 1629, 1654, 1664, 1694, 1716, 1725, 1778, 1803, 1804], [123, 156, 192, 197, 254, 291, 292, 377, 401, 446, 597, 630, 631, 694, 695, 701, 719, 724, 725, 762, 849, 851, 869, 891, 928, 940, 977, 989, 996, 1052, 1072, 1091, 1151, 1155, 1206, 1220, 1242, 1308, 1363, 1524, 1528, 1559, 1606, 1629, 1654, 1664, 1694, 1725, 1778, 1803, 1804], [123, 156, 192, 292, 377, 597, 630, 631, 694, 695, 701, 719, 725, 762, 851, 869, 891, 928, 940, 989, 996, 1072, 1091, 1155, 1206, 1242, 1524, 1528, 1606, 1629, 1654, 1664, 1725, 1804], [377, 597, 630, 631, 725, 762, 869, 928, 940, 989, 996, 1091, 1155, 1242, 1524, 1528, 1629, 1654, 1664, 1804], [597, 630, 631, 869, 928, 940, 989, 1242, 1524, 1654], [869, 940, 1524, 1654]]\n",
            "4\n",
            "[[597, 630, 631, 725, 869, 928, 940, 989, 1242, 1524, 1654, 1664], [869, 1524], [869, 1524], [869, 940, 1524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_N77SkD7mAY"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBl0YdF-ktFs"
      },
      "source": [
        "def rotate_img_set(data_set, angle) : # 10' ~ 90'\n",
        "  rotated_img = []\n",
        "  print(\"rotate \" + str(angle) + \"degree\")\n",
        "  for img in data_set :\n",
        "    m = cv2.getRotationMatrix2D((64, 64), angle, 1)\n",
        "    new_img = cv2.warpAffine(img, m, (128, 128), cv2.INTER_AREA, borderMode = 1)\n",
        "    rotated_img.append(new_img)\n",
        "    \n",
        "  return rotated_img"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j_63itRXpce"
      },
      "source": [
        "def img_trim(img, size) :\n",
        "  w = 128\n",
        "  h = 128\n",
        "  new_img = img[size:size+h, size:size+w]\n",
        "  return new_img"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d025U1ddpf0f"
      },
      "source": [
        "def size_Adjust(x_test, rate) :\n",
        "\n",
        "  new_data_set = []\n",
        "  if rate > 1 : # aggmentation\n",
        "    print(\"augmentation \" + str(rate) + \"%\")\n",
        "    size = round(128*rate/2 - 64)\n",
        "    for img in x_test :\n",
        "      new_img = cv2.resize(img, None, fx = rate, fy = rate, interpolation = cv2.INTER_LINEAR)\n",
        "      new_img = img_trim(new_img, size)\n",
        "      new_data_set.append(new_img)\n",
        "  else :  # reduction\n",
        "    print(\"reduction \" + str(rate) + \"%\")\n",
        "    size = round(64 * (1-rate))\n",
        "    for img in x_test :\n",
        "      new_img = cv2.resize(img, None, fx = rate, fy = rate, interpolation = cv2.INTER_AREA)\n",
        "      new_img = np.pad(new_img, ((size, size), (size, size), (0, 0)), mode = 'edge')\n",
        "      new_img = cv2.resize(new_img, (128, 128), interpolation = cv2.INTER_AREA)\n",
        "      new_data_set.append(new_img)\n",
        "\n",
        "  return new_data_set"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A17nZHELAsk8"
      },
      "source": [
        "def get_MD(y_pred, new_y_pred, y_test) :\n",
        "  MD = []\n",
        "  for i in range(len(y_pred)) :\n",
        "    if np.argmax(y_pred[i]) == np.argmax(y_test[i]) and np.argmax(new_y_pred[i]) != np.argmax(y_test[i]) :\n",
        "      MD.append(i)\n",
        "  print(\"    Find MD : \" + str(len(MD)))\n",
        "  return MD"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvGLsdZi7A9_"
      },
      "source": [
        "def calc_Acc(new_y_pred, y_test) :\n",
        "  cnt = 0\n",
        "  for i in range(len(y_pred)) :\n",
        "    if np.argmax(new_y_pred[i]) == np.argmax(y_test[i]) :\n",
        "      cnt = cnt + 1\n",
        "  acc = cnt/len(y_pred)\n",
        "  print(\"  Acc : \" + str(acc))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVbJ2c76DBfN"
      },
      "source": [
        "def get_PMD_Precision(MD, PMD) :\n",
        "  cnt = 0\n",
        "  if len(PMD) == 0 :\n",
        "    return 0\n",
        "  for data in PMD : \n",
        "    if data in MD :\n",
        "      cnt = cnt + 1\n",
        "  precision = cnt/len(PMD)\n",
        "  print(\"        Precision : \" + str(precision))\n",
        "  return precision"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw8jcHeuDm1I"
      },
      "source": [
        "def get_PMD_Recall(MD, PMD) :\n",
        "  cnt = 0\n",
        "  if len(MD) == 0 :\n",
        "    return 0\n",
        "  for data in MD : \n",
        "    if data in PMD :\n",
        "      cnt = cnt + 1\n",
        "  recall = cnt/len(MD)\n",
        "  print(\"        Recall : \" + str(recall))\n",
        "  return recall"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDi-HHhKMKKb"
      },
      "source": [
        "def get_Result(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, data_set, y_pred, y_test) : #\n",
        "  Stp = []   # [ th = 0.1_pre1, th = 0.2_pre2, ... , th = 0.9_pre9 ] number of elements = 9\n",
        "  Dtp = []   # [ th = min_pre1, th = 95%_pre2, ... , th = 99%_pre4 ] number of elements = 4\n",
        "  Str = []   # [ th = 0.1_rec1, th = 0.2_rec2, ... , th = 0.9_rec9 ] number of elements = 9\n",
        "  Dtr = []   # [ th = min_rec1, th = 95%_rec2, ... , th = 99%_rec4 ] number of elements = 4\n",
        "  st = 1\n",
        "  dt = 1\n",
        "\n",
        "  new_y_pred = model.predict(data_set)\n",
        "  calc_Acc(new_y_pred, y_test)\n",
        "  MD = get_MD(y_pred, new_y_pred, y_test)\n",
        "\n",
        "  print(\"      \" + \"static threshold\")\n",
        "  for s in PMD_By_Static_Threshold :\n",
        "    print(\"        \" + str(st) + \"st static threshold\")\n",
        "    st = st + 1\n",
        "    Stp.append(get_PMD_Precision(MD, s))\n",
        "    Str.append(get_PMD_Recall(MD, s))\n",
        "    print()\n",
        "\n",
        "  print(\"      \" + \"dynamic threshold\")\n",
        "  for d in PMD_By_Dynamic_Threshold :\n",
        "    print(\"        \" + str(dt) + \"st dynamic threshold\")\n",
        "    dt = dt + 1\n",
        "    Dtp.append(get_PMD_Precision(MD, d))\n",
        "    Dtr.append(get_PMD_Recall(MD, d))\n",
        "    print()\n",
        "\n",
        "  return Stp, Dtp, Str, Dtr"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIrGCTsIT0W2"
      },
      "source": [
        "def get_Avg_Result(lists) : #\n",
        "  x = len(lists[0]) # static = 9, dynamic = 4\n",
        "  y = len(lists)    # aggmentation, reduction = 4, rotate = 9\n",
        "  Avg = []\n",
        "\n",
        "  for i in range(x) :\n",
        "    temp = 0\n",
        "    for j in range(y) :\n",
        "      temp = temp + lists[j][i]\n",
        "    Avg.append(temp/y)\n",
        "  return Avg"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IstHpWWqaKbx"
      },
      "source": [
        "def validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_rate, rotated = False) : #\n",
        "\n",
        "  stp_Result = []\n",
        "  dtp_Result = []\n",
        "  str_Result = []\n",
        "  dtr_Result = []\n",
        "\n",
        "  for rate in list_of_rate :\n",
        "    if rotated :\n",
        "      data_set = rotate_img_set(x_test, rate)\n",
        "    else :\n",
        "      data_set = size_Adjust(x_test, rate)\n",
        "    data_set = np.array(data_set)\n",
        "\n",
        "    Stp, Dtp, Str, Dtr = get_Result(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, data_set, y_pred, y_test)\n",
        "    stp_Result.append(Stp)\n",
        "    dtp_Result.append(Dtp)\n",
        "    str_Result.append(Str)\n",
        "    dtr_Result.append(Dtr)\n",
        "\n",
        "  stp_Result = get_Avg_Result(stp_Result)\n",
        "  dtp_Result = get_Avg_Result(dtp_Result)\n",
        "  str_Result = get_Avg_Result(str_Result)\n",
        "  dtr_Result = get_Avg_Result(dtr_Result)\n",
        "  return stp_Result, dtp_Result, str_Result, dtr_Result"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvNLJ7piWSqM"
      },
      "source": [
        "def print_Result(stp_Result, dtp_Result, str_Result, dtr_Result, comments, staticThreshold, dynamicThreshold) :\n",
        "  print(comments)\n",
        "  print(staticThreshold)\n",
        "  print(stp_Result)\n",
        "  print(str_Result)\n",
        "  print(dynamicThreshold)\n",
        "  print(dtp_Result)\n",
        "  print(dtr_Result)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ldORRdSVA6G"
      },
      "source": [
        "list_of_ag_rate = [1.1, 1.2, 1.3, 1.4]\n",
        "list_of_rd_rate = [0.9, 0.8, 0.7, 0.6]\n",
        "list_of_degree = [10, 20, 30, 40, 50, 60 ,70, 80 ,90]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIjZQrrqVDHQ",
        "outputId": "b6148675-d016-41f5-b687-fbca67789d41"
      },
      "source": [
        "rot_Stp, rot_Dtp, rot_Str, rot_Dtr = validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_degree, True)   ## rotated"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rotate 10degree\n",
            "  Acc : 0.74412247129579\n",
            "    Find MD : 113\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.41566265060240964\n",
            "        Recall : 0.6106194690265486\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.44144144144144143\n",
            "        Recall : 0.4336283185840708\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.46511627906976744\n",
            "        Recall : 0.35398230088495575\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.4492753623188406\n",
            "        Recall : 0.2743362831858407\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.5294117647058824\n",
            "        Recall : 0.23893805309734514\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.5294117647058824\n",
            "        Recall : 0.1592920353982301\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.7\n",
            "        Recall : 0.12389380530973451\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.7\n",
            "        Recall : 0.061946902654867256\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.035398230088495575\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.07964601769911504\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.017699115044247787\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.017699115044247787\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.02654867256637168\n",
            "\n",
            "rotate 20degree\n",
            "  Acc : 0.5079278294149808\n",
            "    Find MD : 539\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.6445783132530121\n",
            "        Recall : 0.19851576994434136\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.6666666666666666\n",
            "        Recall : 0.137291280148423\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.7093023255813954\n",
            "        Recall : 0.11317254174397032\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.7101449275362319\n",
            "        Recall : 0.09090909090909091\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.7058823529411765\n",
            "        Recall : 0.06679035250463822\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.6470588235294118\n",
            "        Recall : 0.04081632653061224\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.029684601113172542\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.016697588126159554\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0074211502782931356\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.9166666666666666\n",
            "        Recall : 0.02040816326530612\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0037105751391465678\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0037105751391465678\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0055658627087198514\n",
            "\n",
            "rotate 30degree\n",
            "  Acc : 0.2383816293056315\n",
            "    Find MD : 1028\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.7590361445783133\n",
            "        Recall : 0.122568093385214\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.7747747747747747\n",
            "        Recall : 0.08365758754863813\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.7674418604651163\n",
            "        Recall : 0.06420233463035019\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.7536231884057971\n",
            "        Recall : 0.05058365758754864\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.7254901960784313\n",
            "        Recall : 0.03599221789883268\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.6764705882352942\n",
            "        Recall : 0.02237354085603113\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.014591439688715954\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.008754863813229572\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0038910505836575876\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.8333333333333334\n",
            "        Recall : 0.009727626459143969\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0019455252918287938\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0019455252918287938\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0029182879377431907\n",
            "\n",
            "rotate 40degree\n",
            "  Acc : 0.14270092946965554\n",
            "    Find MD : 1195\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.8373493975903614\n",
            "        Recall : 0.11631799163179916\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.8198198198198198\n",
            "        Recall : 0.07615062761506276\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.8255813953488372\n",
            "        Recall : 0.059414225941422594\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.8260869565217391\n",
            "        Recall : 0.04769874476987448\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.8431372549019608\n",
            "        Recall : 0.03598326359832636\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.8235294117647058\n",
            "        Recall : 0.023430962343096235\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.013389121338912133\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.007531380753138075\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0033472803347280333\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.8333333333333334\n",
            "        Recall : 0.008368200836820083\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0016736401673640166\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0016736401673640166\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.002510460251046025\n",
            "\n",
            "rotate 50degree\n",
            "  Acc : 0.10114816839803172\n",
            "    Find MD : 1261\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.9036144578313253\n",
            "        Recall : 0.11895321173671689\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.918918918918919\n",
            "        Recall : 0.08088818398096749\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.9186046511627907\n",
            "        Recall : 0.0626486915146709\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.927536231884058\n",
            "        Recall : 0.05075337034099921\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.9215686274509803\n",
            "        Recall : 0.03727200634417129\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.9411764705882353\n",
            "        Recall : 0.025376685170499604\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.014274385408406027\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.007930214115781126\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0031720856463124504\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.00951625693893735\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0015860428231562252\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0015860428231562252\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0023790642347343376\n",
            "\n",
            "rotate 60degree\n",
            "  Acc : 0.1016949152542373\n",
            "    Find MD : 1258\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.8795180722891566\n",
            "        Recall : 0.11605723370429252\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.8828828828828829\n",
            "        Recall : 0.07790143084260731\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.8953488372093024\n",
            "        Recall : 0.06120826709062003\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.9130434782608695\n",
            "        Recall : 0.050079491255961846\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.9215686274509803\n",
            "        Recall : 0.037360890302066775\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.9411764705882353\n",
            "        Recall : 0.025437201907790145\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.014308426073131956\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.00794912559618442\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.003179650238473768\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.9166666666666666\n",
            "        Recall : 0.008744038155802861\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.001589825119236884\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.001589825119236884\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0023847376788553257\n",
            "\n",
            "rotate 70degree\n",
            "  Acc : 0.13121924548933844\n",
            "    Find MD : 1210\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.8192771084337349\n",
            "        Recall : 0.11239669421487604\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.8378378378378378\n",
            "        Recall : 0.0768595041322314\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.8372093023255814\n",
            "        Recall : 0.05950413223140496\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.8405797101449275\n",
            "        Recall : 0.047933884297520664\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.8431372549019608\n",
            "        Recall : 0.03553719008264463\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.8823529411764706\n",
            "        Recall : 0.024793388429752067\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.013223140495867768\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.00743801652892562\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.003305785123966942\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.8333333333333334\n",
            "        Recall : 0.008264462809917356\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.001652892561983471\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.001652892561983471\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0024793388429752068\n",
            "\n",
            "rotate 80degree\n",
            "  Acc : 0.18917441224712958\n",
            "    Find MD : 1112\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.8132530120481928\n",
            "        Recall : 0.12140287769784172\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.8198198198198198\n",
            "        Recall : 0.08183453237410072\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.8255813953488372\n",
            "        Recall : 0.06384892086330936\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.8260869565217391\n",
            "        Recall : 0.051258992805755396\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.8235294117647058\n",
            "        Recall : 0.03776978417266187\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.8235294117647058\n",
            "        Recall : 0.025179856115107913\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.014388489208633094\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.008093525179856115\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0035971223021582736\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.8333333333333334\n",
            "        Recall : 0.008992805755395683\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0017985611510791368\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0017985611510791368\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.002697841726618705\n",
            "\n",
            "rotate 90degree\n",
            "  Acc : 0.19245489338436303\n",
            "    Find MD : 1101\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.7590361445783133\n",
            "        Recall : 0.11444141689373297\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.7567567567567568\n",
            "        Recall : 0.07629427792915532\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.7558139534883721\n",
            "        Recall : 0.05903723887375113\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.7536231884057971\n",
            "        Recall : 0.047229791099000905\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.803921568627451\n",
            "        Recall : 0.03723887375113533\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.8235294117647058\n",
            "        Recall : 0.025431425976385105\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.014532243415077202\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.007266121707538601\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.0027247956403269754\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.008174386920980926\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0018165304268846503\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0018165304268846503\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0027247956403269754\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LO8k1sSVGDT",
        "outputId": "8a13a8d2-b65d-450c-af5d-7274ef768c00"
      },
      "source": [
        "ag_Stp, ag_Dtp, ag_Str, ag_Dtr = validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_ag_rate, False)    ## augmentation"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "augmentation 1.1%\n",
            "  Acc : 0.7665390924002187\n",
            "    Find MD : 82\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.29518072289156627\n",
            "        Recall : 0.5975609756097561\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.36036036036036034\n",
            "        Recall : 0.4878048780487805\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.3953488372093023\n",
            "        Recall : 0.4146341463414634\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.391304347826087\n",
            "        Recall : 0.32926829268292684\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.37254901960784315\n",
            "        Recall : 0.23170731707317074\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.35294117647058826\n",
            "        Recall : 0.14634146341463414\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.5\n",
            "        Recall : 0.12195121951219512\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.7\n",
            "        Recall : 0.08536585365853659\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.036585365853658534\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.6666666666666666\n",
            "        Recall : 0.0975609756097561\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 0.5\n",
            "        Recall : 0.012195121951219513\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 0.5\n",
            "        Recall : 0.012195121951219513\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 0.6666666666666666\n",
            "        Recall : 0.024390243902439025\n",
            "\n",
            "augmentation 1.2%\n",
            "  Acc : 0.740295243302351\n",
            "    Find MD : 143\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.35542168674698793\n",
            "        Recall : 0.4125874125874126\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.38738738738738737\n",
            "        Recall : 0.3006993006993007\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.4186046511627907\n",
            "        Recall : 0.2517482517482518\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.4057971014492754\n",
            "        Recall : 0.1958041958041958\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.39215686274509803\n",
            "        Recall : 0.13986013986013987\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.38235294117647056\n",
            "        Recall : 0.09090909090909091\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.55\n",
            "        Recall : 0.07692307692307693\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.6\n",
            "        Recall : 0.04195804195804196\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.25\n",
            "        Recall : 0.006993006993006993\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.5833333333333334\n",
            "        Recall : 0.04895104895104895\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 0.0\n",
            "        Recall : 0.0\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 0.0\n",
            "        Recall : 0.0\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 0.3333333333333333\n",
            "        Recall : 0.006993006993006993\n",
            "\n",
            "augmentation 1.3%\n",
            "  Acc : 0.6801530891197376\n",
            "    Find MD : 260\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.4759036144578313\n",
            "        Recall : 0.3038461538461538\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.5045045045045045\n",
            "        Recall : 0.2153846153846154\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.5232558139534884\n",
            "        Recall : 0.17307692307692307\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.5507246376811594\n",
            "        Recall : 0.14615384615384616\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.5294117647058824\n",
            "        Recall : 0.10384615384615385\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.5\n",
            "        Recall : 0.06538461538461539\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.65\n",
            "        Recall : 0.05\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.03076923076923077\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.011538461538461539\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.03461538461538462\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.007692307692307693\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.007692307692307693\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.011538461538461539\n",
            "\n",
            "augmentation 1.4%\n",
            "  Acc : 0.6079825041006014\n",
            "    Find MD : 389\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.5783132530120482\n",
            "        Recall : 0.2467866323907455\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.6396396396396397\n",
            "        Recall : 0.18251928020565553\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.6511627906976745\n",
            "        Recall : 0.14395886889460155\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.6521739130434783\n",
            "        Recall : 0.11568123393316196\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.6274509803921569\n",
            "        Recall : 0.08226221079691516\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.6470588235294118\n",
            "        Recall : 0.056555269922879174\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.038560411311053984\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.9\n",
            "        Recall : 0.02313624678663239\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.007712082262210797\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.9166666666666666\n",
            "        Recall : 0.028277634961439587\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.005141388174807198\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.005141388174807198\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.007712082262210797\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GJeSp_xVIcI",
        "outputId": "9eb07128-3c05-403d-ee78-cbf6f29fdad6"
      },
      "source": [
        "rd_Stp, rd_Dtp, rd_Str, rd_Dtr = validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_rd_rate, False)   ## reduction"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reduction 0.9%\n",
            "  Acc : 0.7599781301257518\n",
            "    Find MD : 76\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.3433734939759036\n",
            "        Recall : 0.75\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.3963963963963964\n",
            "        Recall : 0.5789473684210527\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.4418604651162791\n",
            "        Recall : 0.5\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.4782608695652174\n",
            "        Recall : 0.4342105263157895\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.49019607843137253\n",
            "        Recall : 0.32894736842105265\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.5294117647058824\n",
            "        Recall : 0.23684210526315788\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.55\n",
            "        Recall : 0.14473684210526316\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.7\n",
            "        Recall : 0.09210526315789473\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.039473684210526314\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.11842105263157894\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 0.5\n",
            "        Recall : 0.013157894736842105\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 0.5\n",
            "        Recall : 0.013157894736842105\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 0.6666666666666666\n",
            "        Recall : 0.02631578947368421\n",
            "\n",
            "reduction 0.8%\n",
            "  Acc : 0.7151448879168945\n",
            "    Find MD : 154\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.4879518072289157\n",
            "        Recall : 0.525974025974026\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.5675675675675675\n",
            "        Recall : 0.4090909090909091\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.6046511627906976\n",
            "        Recall : 0.33766233766233766\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.6376811594202898\n",
            "        Recall : 0.2857142857142857\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.6274509803921569\n",
            "        Recall : 0.2077922077922078\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.6470588235294118\n",
            "        Recall : 0.14285714285714285\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.55\n",
            "        Recall : 0.07142857142857142\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.7\n",
            "        Recall : 0.045454545454545456\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.75\n",
            "        Recall : 0.01948051948051948\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.6666666666666666\n",
            "        Recall : 0.05194805194805195\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.012987012987012988\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.012987012987012988\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.01948051948051948\n",
            "\n",
            "reduction 0.7%\n",
            "  Acc : 0.6440677966101694\n",
            "    Find MD : 289\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.6144578313253012\n",
            "        Recall : 0.35294117647058826\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.6576576576576577\n",
            "        Recall : 0.25259515570934254\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.6744186046511628\n",
            "        Recall : 0.20069204152249134\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.6956521739130435\n",
            "        Recall : 0.16608996539792387\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.6862745098039216\n",
            "        Recall : 0.12110726643598616\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.6764705882352942\n",
            "        Recall : 0.07958477508650519\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.6\n",
            "        Recall : 0.04152249134948097\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.7\n",
            "        Recall : 0.02422145328719723\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 0.5\n",
            "        Recall : 0.006920415224913495\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.6666666666666666\n",
            "        Recall : 0.02768166089965398\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.006920415224913495\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.006920415224913495\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 0.6666666666666666\n",
            "        Recall : 0.006920415224913495\n",
            "\n",
            "reduction 0.6%\n",
            "  Acc : 0.5057408419901586\n",
            "    Find MD : 530\n",
            "      static threshold\n",
            "        1st static threshold\n",
            "        Precision : 0.7771084337349398\n",
            "        Recall : 0.24339622641509434\n",
            "\n",
            "        2st static threshold\n",
            "        Precision : 0.8108108108108109\n",
            "        Recall : 0.16981132075471697\n",
            "\n",
            "        3st static threshold\n",
            "        Precision : 0.8372093023255814\n",
            "        Recall : 0.13584905660377358\n",
            "\n",
            "        4st static threshold\n",
            "        Precision : 0.8115942028985508\n",
            "        Recall : 0.10566037735849057\n",
            "\n",
            "        5st static threshold\n",
            "        Precision : 0.8431372549019608\n",
            "        Recall : 0.08113207547169811\n",
            "\n",
            "        6st static threshold\n",
            "        Precision : 0.8235294117647058\n",
            "        Recall : 0.052830188679245285\n",
            "\n",
            "        7st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.03018867924528302\n",
            "\n",
            "        8st static threshold\n",
            "        Precision : 0.8\n",
            "        Recall : 0.01509433962264151\n",
            "\n",
            "        9st static threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.007547169811320755\n",
            "\n",
            "      dynamic threshold\n",
            "        1st dynamic threshold\n",
            "        Precision : 0.8333333333333334\n",
            "        Recall : 0.018867924528301886\n",
            "\n",
            "        2st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0037735849056603774\n",
            "\n",
            "        3st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.0037735849056603774\n",
            "\n",
            "        4st dynamic threshold\n",
            "        Precision : 1.0\n",
            "        Recall : 0.005660377358490566\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz1I_yWxWm2l",
        "outputId": "3c4ccd85-fd69-43be-9d9c-6e8383691b61"
      },
      "source": [
        "print_Result(rot_Stp, rot_Dtp, rot_Str, rot_Dtr, \"Rotation\", staticThreshold, dynamicThreshold)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rotation\n",
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
            "[0.7590361445783134, 0.7687687687687688, 0.7777777777777778, 0.7777777777777778, 0.7908496732026143, 0.7875816993464052, 0.8055555555555555, 0.8888888888888891, 0.9722222222222222]\n",
            "[0.18125252869281813, 0.12494508257280633, 0.09966873930827279, 0.07897592291684365, 0.06254251463909137, 0.041347935858611615, 0.028031739116850127, 0.014845304275075593, 0.007337461137379193]\n",
            "[0.7434929, 1.04800775514659, 0.9837800629025942, 0.9091536014381421]\n",
            "[0.8518518518518519, 1.0, 1.0, 1.0]\n",
            "[0.01798243987126882, 0.0037191897472141702, 0.0037191897472141702, 0.005578784620821255]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxaGucIFH305",
        "outputId": "c5fb0848-888f-4e96-99e9-e899e98bc781"
      },
      "source": [
        "print_Result(ag_Stp, ag_Dtp, ag_Str, ag_Dtr, \"Augmentation\", staticThreshold, dynamicThreshold)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmentation\n",
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
            "[0.4262048192771084, 0.4729729729729729, 0.497093023255814, 0.5, 0.48039215686274506, 0.47058823529411764, 0.6125, 0.7499999999999999, 0.625]\n",
            "[0.390195293608517, 0.29660201858458796, 0.24585454751530997, 0.1967268921435327, 0.1394189553940949, 0.0897976099078049, 0.0718586769365815, 0.04530734329311043, 0.015707229161834466]\n",
            "[0.7434929, 1.04800775514659, 0.9837800629025942, 0.9091536014381421]\n",
            "[0.7291666666666666, 0.625, 0.625, 0.75]\n",
            "[0.05235126103440732, 0.0062572044545836005, 0.0062572044545836005, 0.012658448674029588]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXdBb1yEH3-s",
        "outputId": "0fd4f587-4477-43a4-d2ef-16a4901bf756"
      },
      "source": [
        "print_Result(rd_Stp, rd_Dtp, rd_Str, rd_Dtr, \"Reduction\", staticThreshold, dynamicThreshold)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reduction\n",
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
            "[0.5557228915662651, 0.6081081081081081, 0.6395348837209303, 0.6557971014492754, 0.6617647058823529, 0.6691176470588236, 0.625, 0.7249999999999999, 0.75]\n",
            "[0.4680778572149272, 0.35261118849400536, 0.29355085894715066, 0.2479187886966224, 0.18474472953023618, 0.1280285529715128, 0.07196914603214964, 0.044218900380569734, 0.01835544718182001]\n",
            "[0.7434929, 1.04800775514659, 0.9837800629025942, 0.9091536014381421]\n",
            "[0.7291666666666666, 0.875, 0.875, 0.8333333333333333]\n",
            "[0.05422967250189669, 0.00920972696360724, 0.00920972696360724, 0.014594275384401938]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}