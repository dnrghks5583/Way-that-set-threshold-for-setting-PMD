{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "caltech101-resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7RlrRDgDVpi1njCHiS6er",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnrghks5583/Way-that-set-threshold-for-setting-PMD/blob/main/caltech101_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jWi9uCNk_xe",
        "outputId": "0e31f1c7-0881-449b-a929-3c68bcbfd90e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6WogO7UlBgr"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "# training parameters\n",
        "batch_size = 32 # orig paper trained all networks with batch_size=128\n",
        "epochs = 100\n",
        "num_classes = 102\n",
        "data_augmentation = True\n",
        "\n",
        "# subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 9\n",
        "\n",
        "# model version\n",
        "# orig paper: version = 1 (ResNet v1), \n",
        "# improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "path = '/content/gdrive/My Drive/caltech101_pickle'\n",
        "image_size = (128, 128)\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 102"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieUuRL6NlHra"
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "with gzip.open('caltech101_x_trainData_128.pickle', 'rb') as f:\n",
        "    x_train = pickle.load(f)\n",
        "    \n",
        "with gzip.open('caltech101_x_testData_128.pickle', 'rb') as f:\n",
        "    x_test = pickle.load(f)\n",
        "    \n",
        "with gzip.open('caltech101_y_trainData_128.pickle', 'rb') as f:\n",
        "    y_train = pickle.load(f)\n",
        "    \n",
        "with gzip.open('caltech101_y_testData_128.pickle', 'rb') as f:\n",
        "    y_test = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_7mb0Y4lKAc",
        "outputId": "3f0ea7f8-06de-45fc-ff09-06cbdc7da1ad"
      },
      "source": [
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# if subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('Model_Type : ' , model_type)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "# convert class vectors to binary class matrices.\n",
        "#y_train = to_categorical(y_train, num_classes)\n",
        "#y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_Type :  ResNet56v1\n",
            "x_train shape: (7316, 128, 128, 3)\n",
            "7316 train samples\n",
            "1829 test samples\n",
            "y_train shape: (7316, 102)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIRE70K9VGjD"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "    Arguments:\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "    Returns:\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=num_classes):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved\n",
        "    (downsampled) by a convolutional layer with strides=2, while \n",
        "    the number of filters is doubled. Within each stage, \n",
        "    the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "    Arguments:\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "    Returns:\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, in [a])')\n",
        "    # start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:\n",
        "                # linear projection residual shortcut\n",
        "                # connection to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=num_classes):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or \n",
        "    also known as bottleneck layer.\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, \n",
        "    the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, \n",
        "    while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have \n",
        "    the same number filters and the same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "    Arguments:\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "    Returns:\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA6jeqZvVJll",
        "outputId": "731ea515-d596-4e91-e2df-dbdda2becb84"
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
        "              metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "# enable this if pydot can be installed\n",
        "# pip install pydot\n",
        "#plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 128, 128, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 128, 128, 16) 64          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 128, 128, 16) 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 128, 128, 16) 2320        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 128, 128, 16) 64          conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 128, 128, 16) 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 128, 128, 16) 2320        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 128, 128, 16) 64          conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 128, 128, 16) 0           activation_55[0][0]              \n",
            "                                                                 batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 128, 128, 16) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 128, 128, 16) 2320        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 128, 128, 16) 64          conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 128, 128, 16) 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 128, 128, 16) 2320        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 128, 128, 16) 64          conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 128, 128, 16) 0           activation_57[0][0]              \n",
            "                                                                 batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 128, 128, 16) 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 128, 128, 16) 2320        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 128, 128, 16) 64          conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 128, 128, 16) 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 128, 128, 16) 2320        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 128, 128, 16) 64          conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 128, 128, 16) 0           activation_59[0][0]              \n",
            "                                                                 batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 128, 128, 16) 0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 128, 128, 16) 2320        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 128, 128, 16) 64          conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 128, 128, 16) 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 128, 128, 16) 2320        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 128, 128, 16) 64          conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 128, 128, 16) 0           activation_61[0][0]              \n",
            "                                                                 batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 128, 128, 16) 0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 128, 128, 16) 2320        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 128, 128, 16) 64          conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 128, 128, 16) 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 128, 128, 16) 2320        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 128, 128, 16) 64          conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 128, 128, 16) 0           activation_63[0][0]              \n",
            "                                                                 batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 128, 128, 16) 0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 128, 128, 16) 2320        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 128, 128, 16) 64          conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 128, 128, 16) 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 128, 128, 16) 2320        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 128, 128, 16) 64          conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 128, 128, 16) 0           activation_65[0][0]              \n",
            "                                                                 batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 128, 128, 16) 0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 128, 128, 16) 2320        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 128, 128, 16) 64          conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 128, 128, 16) 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 128, 128, 16) 2320        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 128, 128, 16) 64          conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 128, 128, 16) 0           activation_67[0][0]              \n",
            "                                                                 batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 128, 128, 16) 0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 128, 128, 16) 2320        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 128, 128, 16) 64          conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 128, 128, 16) 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 128, 128, 16) 2320        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 128, 128, 16) 64          conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 128, 128, 16) 0           activation_69[0][0]              \n",
            "                                                                 batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 128, 128, 16) 0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 128, 128, 16) 2320        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 128, 128, 16) 64          conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 128, 128, 16) 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 128, 128, 16) 2320        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 128, 128, 16) 64          conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 128, 128, 16) 0           activation_71[0][0]              \n",
            "                                                                 batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 128, 128, 16) 0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 64, 64, 32)   4640        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 64, 64, 32)   128         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 64, 64, 32)   0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 64, 64, 32)   9248        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 64, 64, 32)   544         activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 64, 64, 32)   128         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 64, 64, 32)   0           conv2d_78[0][0]                  \n",
            "                                                                 batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 64, 64, 32)   0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 64, 64, 32)   9248        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 64, 64, 32)   128         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 64, 64, 32)   0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 64, 64, 32)   9248        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 64, 64, 32)   128         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 64, 64, 32)   0           activation_75[0][0]              \n",
            "                                                                 batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 64, 64, 32)   0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 64, 64, 32)   9248        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 64, 64, 32)   128         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 64, 64, 32)   0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 64, 64, 32)   9248        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 64, 64, 32)   128         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 64, 64, 32)   0           activation_77[0][0]              \n",
            "                                                                 batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 64, 64, 32)   0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 64, 64, 32)   9248        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 64, 64, 32)   128         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 64, 64, 32)   0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 64, 64, 32)   9248        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 64, 64, 32)   128         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 64, 64, 32)   0           activation_79[0][0]              \n",
            "                                                                 batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 64, 64, 32)   0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 64, 64, 32)   9248        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 64, 64, 32)   128         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 64, 64, 32)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 64, 64, 32)   9248        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 64, 64, 32)   128         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 64, 64, 32)   0           activation_81[0][0]              \n",
            "                                                                 batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 64, 64, 32)   0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 64, 64, 32)   9248        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 64, 64, 32)   128         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 64, 64, 32)   0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 64, 64, 32)   9248        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 64, 64, 32)   128         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 64, 64, 32)   0           activation_83[0][0]              \n",
            "                                                                 batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 64, 64, 32)   0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 64, 64, 32)   9248        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 64, 64, 32)   128         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 64, 64, 32)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 64, 64, 32)   9248        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 64, 64, 32)   128         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 64, 64, 32)   0           activation_85[0][0]              \n",
            "                                                                 batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 64, 64, 32)   0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 64, 64, 32)   9248        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 64, 64, 32)   128         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 64, 64, 32)   0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 64, 64, 32)   9248        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 64, 64, 32)   128         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 64, 64, 32)   0           activation_87[0][0]              \n",
            "                                                                 batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 64, 64, 32)   0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 64, 64, 32)   9248        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 64, 64, 32)   128         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 64, 64, 32)   0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 64, 64, 32)   9248        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 64, 64, 32)   128         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 64, 64, 32)   0           activation_89[0][0]              \n",
            "                                                                 batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 64, 64, 32)   0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 32, 32, 64)   18496       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 32, 32, 64)   256         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 32, 32, 64)   0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 32, 32, 64)   36928       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 32, 32, 64)   2112        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 32, 32, 64)   256         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 32, 32, 64)   0           conv2d_97[0][0]                  \n",
            "                                                                 batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 32, 32, 64)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 32, 32, 64)   36928       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 32, 32, 64)   256         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 32, 32, 64)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 32, 32, 64)   36928       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 32, 32, 64)   256         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 32, 32, 64)   0           activation_93[0][0]              \n",
            "                                                                 batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 32, 32, 64)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 32, 32, 64)   36928       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 32, 32, 64)   256         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 32, 32, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 32, 32, 64)   36928       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 32, 32, 64)   256         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 32, 32, 64)   0           activation_95[0][0]              \n",
            "                                                                 batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 32, 32, 64)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 32, 32, 64)   36928       activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 32, 32, 64)   256         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 32, 32, 64)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 32, 32, 64)   36928       activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 32, 32, 64)   256         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 32, 32, 64)   0           activation_97[0][0]              \n",
            "                                                                 batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 32, 32, 64)   0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 32, 32, 64)   36928       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 32, 32, 64)   256         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 32, 32, 64)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 64)   36928       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 32, 32, 64)   256         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 32, 32, 64)   0           activation_99[0][0]              \n",
            "                                                                 batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 32, 32, 64)   0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 64)   36928       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 32, 32, 64)   256         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 32, 32, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 64)   36928       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 32, 32, 64)   256         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 32, 32, 64)   0           activation_101[0][0]             \n",
            "                                                                 batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 32, 32, 64)   0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 64)   36928       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 64)   256         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 64)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 64)   36928       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 64)   256         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 32, 32, 64)   0           activation_103[0][0]             \n",
            "                                                                 batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 64)   0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 64)   36928       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 64)   256         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 64)   36928       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 64)   256         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 32, 32, 64)   0           activation_105[0][0]             \n",
            "                                                                 batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 64)   0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 64)   36928       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 64)   256         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 64)   256         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 32, 32, 64)   0           activation_107[0][0]             \n",
            "                                                                 batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 64)   0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 4, 4, 64)     0           activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1024)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 102)          104550      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 965,670\n",
            "Trainable params: 961,606\n",
            "Non-trainable params: 4,064\n",
            "__________________________________________________________________________________________________\n",
            "ResNet56v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bay8BsPVfcr",
        "outputId": "4b566383-d4d8-4d09-b15f-69815ba327a2"
      },
      "source": [
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [lr_reducer, lr_scheduler]\n",
        "#callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7AvdECbVgZA",
        "outputId": "2b2e1d5f-a58f-44fa-94b4-414fb30b9d1b"
      },
      "source": [
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)\n",
        "\n",
        "steps_per_epoch =  math.ceil(len(x_train) / batch_size)\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "model.fit(x=datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "              verbose=1,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              callbacks=callbacks)\n",
        "\n",
        "\n",
        "# score trained model\n",
        "scores = model.evaluate(x_test,\n",
        "                        y_test,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=0)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 81s 314ms/step - loss: 4.6386 - acc: 0.2295 - val_loss: 4.1557 - val_acc: 0.2061\n",
            "Epoch 2/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 3.4529 - acc: 0.3403 - val_loss: 3.1888 - val_acc: 0.3953\n",
            "Epoch 3/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 2.9957 - acc: 0.4076 - val_loss: 3.0022 - val_acc: 0.4204\n",
            "Epoch 4/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 2.6473 - acc: 0.4691 - val_loss: 6.3543 - val_acc: 0.3341\n",
            "Epoch 5/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 2.3753 - acc: 0.5198 - val_loss: 2.3350 - val_acc: 0.5451\n",
            "Epoch 6/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 2.2002 - acc: 0.5500 - val_loss: 2.1537 - val_acc: 0.5692\n",
            "Epoch 7/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 2.0168 - acc: 0.5842 - val_loss: 2.1383 - val_acc: 0.5730\n",
            "Epoch 8/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 320ms/step - loss: 1.8952 - acc: 0.6054 - val_loss: 2.5035 - val_acc: 0.5714\n",
            "Epoch 9/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.7618 - acc: 0.6296 - val_loss: 2.1525 - val_acc: 0.5604\n",
            "Epoch 10/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 1.6574 - acc: 0.6493 - val_loss: 2.1054 - val_acc: 0.5845\n",
            "Epoch 11/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 1.5761 - acc: 0.6681 - val_loss: 1.9091 - val_acc: 0.6211\n",
            "Epoch 12/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 1.4986 - acc: 0.6856 - val_loss: 1.9585 - val_acc: 0.6293\n",
            "Epoch 13/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.4162 - acc: 0.6978 - val_loss: 1.8144 - val_acc: 0.6337\n",
            "Epoch 14/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 1.3673 - acc: 0.7038 - val_loss: 2.0599 - val_acc: 0.6217\n",
            "Epoch 15/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.3034 - acc: 0.7176 - val_loss: 3.1934 - val_acc: 0.5834\n",
            "Epoch 16/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 316ms/step - loss: 1.2475 - acc: 0.7344 - val_loss: 1.6333 - val_acc: 0.6780\n",
            "Epoch 17/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.2015 - acc: 0.7452 - val_loss: 1.6751 - val_acc: 0.6468\n",
            "Epoch 18/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 320ms/step - loss: 1.1567 - acc: 0.7519 - val_loss: 1.7826 - val_acc: 0.6331\n",
            "Epoch 19/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.1006 - acc: 0.7661 - val_loss: 1.7064 - val_acc: 0.6659\n",
            "Epoch 20/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.0525 - acc: 0.7793 - val_loss: 1.6901 - val_acc: 0.6687\n",
            "Epoch 21/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.0250 - acc: 0.7783 - val_loss: 6.2427 - val_acc: 0.4636\n",
            "Epoch 22/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 1.0040 - acc: 0.7859 - val_loss: 1.9981 - val_acc: 0.6424\n",
            "Epoch 23/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.9551 - acc: 0.7963 - val_loss: 1.5695 - val_acc: 0.7009\n",
            "Epoch 24/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.9310 - acc: 0.8004 - val_loss: 1.6401 - val_acc: 0.6796\n",
            "Epoch 25/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.9094 - acc: 0.8092 - val_loss: 2.3561 - val_acc: 0.6627\n",
            "Epoch 26/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.8919 - acc: 0.8071 - val_loss: 1.6677 - val_acc: 0.6823\n",
            "Epoch 27/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.8581 - acc: 0.8196 - val_loss: 1.6206 - val_acc: 0.6884\n",
            "Epoch 28/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.8325 - acc: 0.8227 - val_loss: 1.5370 - val_acc: 0.7086\n",
            "Epoch 29/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.8171 - acc: 0.8293 - val_loss: 1.5116 - val_acc: 0.7031\n",
            "Epoch 30/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.7865 - acc: 0.8357 - val_loss: 1.5808 - val_acc: 0.6993\n",
            "Epoch 31/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.7650 - acc: 0.8408 - val_loss: 1.7782 - val_acc: 0.6993\n",
            "Epoch 32/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.7705 - acc: 0.8364 - val_loss: 1.6188 - val_acc: 0.6851\n",
            "Epoch 33/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.7449 - acc: 0.8472 - val_loss: 1.7275 - val_acc: 0.6894\n",
            "Epoch 34/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.7073 - acc: 0.8555 - val_loss: 1.5962 - val_acc: 0.6867\n",
            "Epoch 35/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.6915 - acc: 0.8584 - val_loss: 1.7633 - val_acc: 0.7075\n",
            "Epoch 36/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.6488 - acc: 0.8721 - val_loss: 1.5690 - val_acc: 0.7059\n",
            "Epoch 37/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.6863 - acc: 0.8552 - val_loss: 1.8969 - val_acc: 0.6911\n",
            "Epoch 38/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.6427 - acc: 0.8729 - val_loss: 1.6821 - val_acc: 0.6993\n",
            "Epoch 39/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.6891 - acc: 0.8533 - val_loss: 3.4908 - val_acc: 0.5648\n",
            "Epoch 40/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.6633 - acc: 0.8658 - val_loss: 1.6197 - val_acc: 0.7086\n",
            "Epoch 41/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.6149 - acc: 0.8807 - val_loss: 3.6900 - val_acc: 0.5435\n",
            "Epoch 42/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.6019 - acc: 0.8826 - val_loss: 2.5225 - val_acc: 0.7119\n",
            "Epoch 43/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.6207 - acc: 0.8790 - val_loss: 3.0297 - val_acc: 0.7141\n",
            "Epoch 44/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.5749 - acc: 0.8886 - val_loss: 1.7440 - val_acc: 0.7031\n",
            "Epoch 45/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.5690 - acc: 0.8901 - val_loss: 1.9347 - val_acc: 0.6676\n",
            "Epoch 46/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.5675 - acc: 0.8893 - val_loss: 1.8468 - val_acc: 0.6807\n",
            "Epoch 47/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.5314 - acc: 0.9013 - val_loss: 2.2859 - val_acc: 0.6566\n",
            "Epoch 48/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.5241 - acc: 0.9020 - val_loss: 1.5520 - val_acc: 0.7244\n",
            "Epoch 49/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.5483 - acc: 0.8969 - val_loss: 2.8306 - val_acc: 0.6408\n",
            "Epoch 50/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.5407 - acc: 0.8963 - val_loss: 2.2775 - val_acc: 0.6714\n",
            "Epoch 51/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.5340 - acc: 0.9002 - val_loss: 1.6344 - val_acc: 0.7020\n",
            "Epoch 52/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.4907 - acc: 0.9117 - val_loss: 1.6497 - val_acc: 0.7037\n",
            "Epoch 53/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.5045 - acc: 0.9028 - val_loss: 1.7032 - val_acc: 0.7151\n",
            "Epoch 54/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.5239 - acc: 0.8950 - val_loss: 3.7820 - val_acc: 0.6736\n",
            "Epoch 55/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4837 - acc: 0.9122 - val_loss: 1.6385 - val_acc: 0.7212\n",
            "Epoch 56/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4695 - acc: 0.9173 - val_loss: 1.5296 - val_acc: 0.7272\n",
            "Epoch 57/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.4557 - acc: 0.9200 - val_loss: 75.2397 - val_acc: 0.5506\n",
            "Epoch 58/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.4608 - acc: 0.9191 - val_loss: 1.5799 - val_acc: 0.7310\n",
            "Epoch 59/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.4586 - acc: 0.9159 - val_loss: 1.7799 - val_acc: 0.7179\n",
            "Epoch 60/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4515 - acc: 0.9206 - val_loss: 2.0133 - val_acc: 0.6916\n",
            "Epoch 61/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.4538 - acc: 0.9184 - val_loss: 1.7201 - val_acc: 0.7042\n",
            "Epoch 62/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.4253 - acc: 0.9255 - val_loss: 2.0889 - val_acc: 0.6867\n",
            "Epoch 63/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4308 - acc: 0.9241 - val_loss: 1.8732 - val_acc: 0.7037\n",
            "Epoch 64/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4331 - acc: 0.9233 - val_loss: 1.5809 - val_acc: 0.7217\n",
            "Epoch 65/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4329 - acc: 0.9204 - val_loss: 1.6234 - val_acc: 0.7288\n",
            "Epoch 66/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4268 - acc: 0.9235 - val_loss: 2.3835 - val_acc: 0.6534\n",
            "Epoch 67/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.4103 - acc: 0.9286 - val_loss: 1.7811 - val_acc: 0.7190\n",
            "Epoch 68/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4226 - acc: 0.9289 - val_loss: 1.5720 - val_acc: 0.7359\n",
            "Epoch 69/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4119 - acc: 0.9265 - val_loss: 1.7260 - val_acc: 0.7102\n",
            "Epoch 70/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.4253 - acc: 0.9232 - val_loss: 1.6473 - val_acc: 0.7272\n",
            "Epoch 71/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.3817 - acc: 0.9348 - val_loss: 2.1422 - val_acc: 0.6840\n",
            "Epoch 72/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.3960 - acc: 0.9322 - val_loss: 1.7566 - val_acc: 0.7141\n",
            "Epoch 73/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.3953 - acc: 0.9317 - val_loss: 5.6520 - val_acc: 0.6621\n",
            "Epoch 74/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.4065 - acc: 0.9293 - val_loss: 1.8430 - val_acc: 0.7113\n",
            "Epoch 75/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.4012 - acc: 0.9293 - val_loss: 8.9327 - val_acc: 0.6288\n",
            "Epoch 76/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.3757 - acc: 0.9381 - val_loss: 1.7154 - val_acc: 0.7135\n",
            "Epoch 77/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 73s 317ms/step - loss: 0.3584 - acc: 0.9412 - val_loss: 1.6930 - val_acc: 0.7321\n",
            "Epoch 78/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.3778 - acc: 0.9363 - val_loss: 1.8937 - val_acc: 0.7004\n",
            "Epoch 79/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.3708 - acc: 0.9404 - val_loss: 1.7648 - val_acc: 0.7053\n",
            "Epoch 80/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.3991 - acc: 0.9276 - val_loss: 1.6846 - val_acc: 0.7255\n",
            "Epoch 81/100\n",
            "Learning rate:  0.001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.3678 - acc: 0.9429 - val_loss: 1.7603 - val_acc: 0.7124\n",
            "Epoch 82/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 313ms/step - loss: 0.2923 - acc: 0.9632 - val_loss: 1.4763 - val_acc: 0.7540\n",
            "Epoch 83/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.2580 - acc: 0.9762 - val_loss: 1.4700 - val_acc: 0.7622\n",
            "Epoch 84/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.2516 - acc: 0.9788 - val_loss: 1.4645 - val_acc: 0.7654\n",
            "Epoch 85/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.2404 - acc: 0.9814 - val_loss: 1.4606 - val_acc: 0.7627\n",
            "Epoch 86/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.2367 - acc: 0.9810 - val_loss: 1.4791 - val_acc: 0.7622\n",
            "Epoch 87/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 315ms/step - loss: 0.2291 - acc: 0.9840 - val_loss: 1.4660 - val_acc: 0.7627\n",
            "Epoch 88/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.2242 - acc: 0.9841 - val_loss: 1.5075 - val_acc: 0.7572\n",
            "Epoch 89/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.2299 - acc: 0.9820 - val_loss: 1.4839 - val_acc: 0.7638\n",
            "Epoch 90/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.2184 - acc: 0.9855 - val_loss: 1.5016 - val_acc: 0.7649\n",
            "Epoch 91/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.2171 - acc: 0.9854 - val_loss: 1.4516 - val_acc: 0.7665\n",
            "Epoch 92/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.2184 - acc: 0.9835 - val_loss: 1.4830 - val_acc: 0.7633\n",
            "Epoch 93/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.2102 - acc: 0.9874 - val_loss: 1.4673 - val_acc: 0.7594\n",
            "Epoch 94/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.2042 - acc: 0.9881 - val_loss: 1.4984 - val_acc: 0.7611\n",
            "Epoch 95/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.2069 - acc: 0.9866 - val_loss: 1.5210 - val_acc: 0.7654\n",
            "Epoch 96/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.2033 - acc: 0.9874 - val_loss: 1.4946 - val_acc: 0.7671\n",
            "Epoch 97/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.1996 - acc: 0.9892 - val_loss: 1.4933 - val_acc: 0.7715\n",
            "Epoch 98/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 73s 319ms/step - loss: 0.1966 - acc: 0.9877 - val_loss: 1.4886 - val_acc: 0.7638\n",
            "Epoch 99/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 73s 318ms/step - loss: 0.1954 - acc: 0.9895 - val_loss: 1.5040 - val_acc: 0.7676\n",
            "Epoch 100/100\n",
            "Learning rate:  0.0001\n",
            "229/229 [==============================] - 72s 314ms/step - loss: 0.1954 - acc: 0.9877 - val_loss: 1.5088 - val_acc: 0.7654\n",
            "Test loss: 1.5088434219360352\n",
            "Test accuracy: 0.7654455900192261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD5fammJlQn5",
        "outputId": "6413744d-ed29-4be2-cd91-c102d17a0f2c"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58/58 [==============================] - 4s 76ms/step - loss: 1.5088 - acc: 0.7654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5088434219360352, 0.7654455900192261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL5ZVMO2LU1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3340e4-e9af-4e56-8d7e-2d87d513fb4e"
      },
      "source": [
        "import tensorflow\n",
        "\n",
        "cce = tensorflow.keras.losses.categorical_crossentropy(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    from_logits = False,\n",
        "    label_smoothing = 0)\n",
        "cce = cce.numpy()\n",
        "print(cce)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.4230405e-02 1.1920930e-07 1.1920930e-07 ... 4.3747479e-01 1.1424823e-01\n",
            " 6.4567733e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xegYf1h2GJ5D"
      },
      "source": [
        "def classification_Cce(cce, y_test, y_pred) :\n",
        "  c = []\n",
        "  m = []\n",
        "  c_i = []\n",
        "\n",
        "  for i in range(len(y_test)) :\n",
        "    if np.argmax(y_test[i]) == np.argmax(y_pred[i]) :\n",
        "      c.append(cce[i])\n",
        "      c_i.append(i)\n",
        "    else :\n",
        "      m.append(cce[i])\n",
        "\n",
        "  return c, m, c_i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFxioRCHHV4z",
        "outputId": "447e3f13-d5d3-4b41-cdc4-1d26f5fe0ba7"
      },
      "source": [
        "collect_Cce, missclassification_Cce, collect_Idx = classification_Cce(cce, y_test, y_pred)\n",
        "print(len(collect_Cce))\n",
        "print(len(missclassification_Cce))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1400\n",
            "429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJc72ue5906W"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TuUqxGNmFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1587631a-bea9-43cf-97df-eca391432ff1"
      },
      "source": [
        "x_value = []\n",
        "for i in range(len(collect_Cce)) :\n",
        "  x_value.append(i)\n",
        "\n",
        "plt.scatter(x_value, collect_Cce)\n",
        "plt.title('Collected data cross entropy')\n",
        "plt.xlabel('index')\n",
        "plt.ylabel('cross entropy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGUHUdl8OHaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ec24f745-8817-43c9-8267-dd4e64eefa26"
      },
      "source": [
        "X_value = []\n",
        "for i in range(len(missclassification_Cce)) :\n",
        "  X_value.append(i)\n",
        "\n",
        "plt.scatter(X_value, missclassification_Cce)\n",
        "plt.title('Missclassification data cross entropy')\n",
        "plt.xlabel('index')\n",
        "plt.ylabel('cross entropy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "tbtbh25Y-Zy4",
        "outputId": "ef7225c1-ca9c-4ab3-b4c2-fc298a8a965a"
      },
      "source": [
        "Y = []\n",
        "for i in range(len(collect_Cce)) :\n",
        "  Y.append(1)\n",
        "y = []\n",
        "for i in range(len(missclassification_Cce)) :\n",
        "  y.append(0)\n",
        "\n",
        "values = [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10, 11, 12 ,13, 14, 15, 16]\n",
        "\n",
        "plt.plot(collect_Cce, Y, 'b^', missclassification_Cce, y, 'r^')\n",
        "plt.title('Cross entropy')\n",
        "plt.xlabel('index')\n",
        "plt.ylabel('cross entropy')\n",
        "plt.legend(['Collect', 'Miss'])\n",
        "plt.yticks([1,0])\n",
        "plt.xticks(values)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yOIVHOpYL_Z",
        "outputId": "954619cf-620e-47d4-80ad-552ac6de76cf"
      },
      "source": [
        "print(max(collect_Cce))\n",
        "print(min(missclassification_Cce))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2613289\n",
            "0.74587244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2urcrdC3bn3J"
      },
      "source": [
        "def static_Threshold() :\n",
        "  threshold = []\n",
        "  for i in range(1, 10):\n",
        "    threshold.append(round(i * 0.1, 1))\n",
        "  return threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUdZfL9CcsW9",
        "outputId": "e76642cd-0237-4ae1-c547-3159cfaaed36"
      },
      "source": [
        "staticThreshold = static_Threshold()\n",
        "print(staticThreshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GuX1afKcWzk"
      },
      "source": [
        "def dynamic_Threshold(missclassification_Cce) :\n",
        "  #Z = [1.96, 2.17, 2.576] # 95%, 97%, 99% two-tails\n",
        "  Z = [1.645, 1.96, 2.326] # 95%, 97.5%, 99% one-tails\n",
        "  threshold = [min(missclassification_Cce)]\n",
        "  x_ = np.mean(missclassification_Cce)\n",
        "  o = np.std(missclassification_Cce)\n",
        "  n_ = (len(missclassification_Cce))**0.5\n",
        "\n",
        "  for z in Z :\n",
        "    threshold.append(x_- (z * o)/n_)\n",
        "  \n",
        "  return threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9dMgr3ehAMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db558663-8bf9-4762-830f-9d19ce29b2f8"
      },
      "source": [
        "dynamicThreshold = dynamic_Threshold(missclassification_Cce)\n",
        "print(dynamicThreshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.74587244, 5.185324421156891, 5.125026945426301, 5.054967021244092]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6HhUB1vhVK_"
      },
      "source": [
        "def detection(threshold, cce, collect) : \n",
        "  PMD = []\n",
        "  for i in collect :\n",
        "    if cce[i] > threshold :\n",
        "        PMD.append(i)\n",
        "  return PMD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9uUzEC1h4na"
      },
      "source": [
        "def detection_PMD(list_of_threshold, cce, collect):\n",
        "  PMD_by_threshold = []\n",
        "\n",
        "  for th in list_of_threshold :\n",
        "    PMD_by_threshold.append(detection(th, cce, collect))\n",
        "  return PMD_by_threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsVPum8jkUL_"
      },
      "source": [
        "PMD_By_Static_Threshold  = detection_PMD(staticThreshold, cce, collect_Idx)\n",
        "PMD_By_Dynamic_Threshold = detection_PMD(dynamicThreshold, cce, collect_Idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y36FANL0kxIC",
        "outputId": "aa6d620d-0a39-4753-acd4-d61fe005af6d"
      },
      "source": [
        "print(len(PMD_By_Static_Threshold))\n",
        "print(PMD_By_Static_Threshold)\n",
        "print(len(PMD_By_Dynamic_Threshold))\n",
        "print(PMD_By_Dynamic_Threshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[6, 12, 13, 26, 28, 31, 32, 41, 64, 94, 96, 111, 112, 118, 120, 131, 137, 146, 149, 182, 184, 198, 239, 241, 242, 256, 267, 270, 274, 276, 308, 316, 330, 345, 352, 376, 377, 403, 404, 409, 422, 445, 458, 461, 465, 471, 501, 504, 513, 527, 559, 580, 581, 583, 585, 590, 612, 615, 629, 631, 662, 665, 671, 687, 700, 706, 723, 730, 758, 763, 778, 792, 805, 810, 812, 814, 823, 826, 829, 840, 844, 850, 851, 860, 871, 891, 892, 903, 918, 927, 929, 940, 951, 955, 988, 992, 998, 1032, 1062, 1071, 1097, 1117, 1121, 1131, 1147, 1155, 1164, 1172, 1209, 1210, 1212, 1220, 1221, 1224, 1227, 1228, 1237, 1238, 1242, 1253, 1269, 1272, 1291, 1326, 1332, 1369, 1370, 1371, 1375, 1384, 1400, 1430, 1436, 1437, 1442, 1472, 1481, 1513, 1528, 1590, 1609, 1619, 1625, 1627, 1632, 1659, 1664, 1690, 1713, 1714, 1730, 1739, 1747, 1762, 1772, 1816, 1824, 1826, 1827, 1828], [6, 12, 26, 28, 31, 41, 64, 94, 111, 120, 131, 137, 146, 149, 182, 184, 198, 241, 256, 267, 274, 308, 316, 330, 376, 377, 403, 409, 422, 458, 504, 513, 580, 581, 585, 590, 612, 615, 631, 662, 665, 671, 687, 700, 706, 723, 730, 758, 778, 792, 810, 812, 814, 826, 840, 844, 851, 860, 871, 891, 892, 903, 918, 927, 929, 940, 955, 988, 992, 998, 1062, 1071, 1117, 1121, 1155, 1209, 1210, 1212, 1220, 1227, 1228, 1238, 1242, 1272, 1326, 1332, 1369, 1370, 1430, 1436, 1437, 1442, 1472, 1481, 1513, 1528, 1590, 1609, 1625, 1632, 1659, 1664, 1690, 1714, 1730, 1772, 1816, 1824, 1826, 1828], [12, 26, 28, 31, 41, 64, 94, 111, 120, 131, 137, 146, 149, 182, 184, 256, 267, 274, 316, 330, 376, 377, 403, 422, 458, 504, 513, 580, 581, 585, 612, 615, 631, 662, 665, 671, 706, 723, 730, 778, 792, 810, 812, 814, 826, 840, 844, 860, 891, 892, 903, 918, 927, 929, 940, 955, 992, 998, 1071, 1117, 1121, 1155, 1209, 1212, 1220, 1228, 1238, 1242, 1272, 1332, 1369, 1430, 1436, 1437, 1442, 1481, 1528, 1590, 1609, 1625, 1632, 1664, 1690, 1714, 1772, 1816, 1824, 1826, 1828], [12, 26, 28, 31, 41, 64, 94, 111, 120, 131, 137, 149, 182, 184, 256, 267, 316, 376, 377, 403, 422, 458, 504, 513, 580, 581, 585, 612, 615, 665, 706, 723, 730, 778, 792, 812, 840, 860, 892, 903, 918, 927, 929, 955, 992, 998, 1117, 1121, 1212, 1228, 1238, 1242, 1272, 1332, 1442, 1528, 1590, 1609, 1625, 1632, 1664, 1690, 1714, 1772, 1816, 1824, 1826, 1828], [12, 26, 28, 31, 41, 64, 94, 111, 120, 131, 149, 182, 184, 267, 376, 377, 403, 422, 458, 504, 513, 580, 612, 615, 665, 723, 730, 778, 792, 812, 840, 860, 903, 927, 929, 955, 992, 998, 1117, 1121, 1228, 1242, 1272, 1332, 1442, 1590, 1609, 1625, 1664, 1690, 1772, 1816, 1824, 1828], [12, 26, 31, 64, 94, 120, 149, 184, 376, 403, 458, 504, 612, 615, 665, 723, 730, 778, 792, 840, 860, 903, 929, 955, 992, 998, 1117, 1228, 1242, 1272, 1332, 1442, 1590, 1609, 1625, 1664, 1824, 1828], [31, 64, 94, 120, 149, 376, 458, 504, 612, 615, 665, 778, 792, 903, 929, 1117, 1228, 1332, 1442, 1625, 1664], [64, 94, 120, 376, 458, 504, 615, 665, 778, 903, 1332, 1625], [64, 94, 120, 376, 615]]\n",
            "4\n",
            "[[31, 64, 94, 120, 376, 458, 504, 615, 665, 778, 792, 903, 1117, 1332, 1625, 1664], [], [], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_N77SkD7mAY"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBl0YdF-ktFs"
      },
      "source": [
        "def rotate_img_set(data_set, angle) : # 10' ~ 90'\n",
        "  rotated_img = []\n",
        "  print(\"rotate \" + str(angle) + \"degree\")\n",
        "  for img in data_set :\n",
        "    m = cv2.getRotationMatrix2D((64, 64), angle, 1)\n",
        "    new_img = cv2.warpAffine(img, m, (128, 128), cv2.INTER_AREA, borderMode = 1)\n",
        "    rotated_img.append(new_img)\n",
        "    \n",
        "  return rotated_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j_63itRXpce"
      },
      "source": [
        "def img_trim(img, size) :\n",
        "  w = 128\n",
        "  h = 128\n",
        "  new_img = img[size:size+h, size:size+w]\n",
        "  return new_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d025U1ddpf0f"
      },
      "source": [
        "def size_Adjust(x_test, rate) :\n",
        "\n",
        "  new_data_set = []\n",
        "  if rate > 1 : # aggmentation\n",
        "    print(\"augmentation \" + str(rate) + \"%\")\n",
        "    size = round(128*rate/2 - 64)\n",
        "    for img in x_test :\n",
        "      new_img = cv2.resize(img, None, fx = rate, fy = rate, interpolation = cv2.INTER_LINEAR)\n",
        "      new_img = img_trim(new_img, size)\n",
        "      new_data_set.append(new_img)\n",
        "  else :  # reduction\n",
        "    print(\"reduction \" + str(rate) + \"%\")\n",
        "    size = round(64 * (1-rate))\n",
        "    for img in x_test :\n",
        "      new_img = cv2.resize(img, None, fx = rate, fy = rate, interpolation = cv2.INTER_AREA)\n",
        "      new_img = np.pad(new_img, ((size, size), (size, size), (0, 0)), mode = 'edge')\n",
        "      new_img = cv2.resize(new_img, (128, 128), interpolation = cv2.INTER_AREA)\n",
        "      new_data_set.append(new_img)\n",
        "\n",
        "  return new_data_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A17nZHELAsk8"
      },
      "source": [
        "def get_MD(y_pred, new_y_pred, y_test) :\n",
        "  MD = []\n",
        "  for i in range(len(y_pred)) :\n",
        "    if np.argmax(y_pred[i]) == np.argmax(y_test[i]) and np.argmax(new_y_pred[i]) != np.argmax(y_test[i]) :\n",
        "      MD.append(i)\n",
        "  return MD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVbJ2c76DBfN"
      },
      "source": [
        "def get_PMD_Precision(MD, PMD) :\n",
        "  cnt = 0\n",
        "  if len(PMD) == 0 :\n",
        "    return 0\n",
        "  for data in PMD : \n",
        "    if data in MD :\n",
        "      cnt = cnt + 1\n",
        "  return cnt/len(PMD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw8jcHeuDm1I"
      },
      "source": [
        "def get_PMD_Recall(MD, PMD) :\n",
        "  cnt = 0\n",
        "  if len(MD) == 0 :\n",
        "    return 0\n",
        "  for data in MD : \n",
        "    if data in PMD :\n",
        "      cnt = cnt + 1\n",
        "  return cnt/len(MD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDi-HHhKMKKb"
      },
      "source": [
        "def get_Result(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, data_set, y_pred, y_test) : #\n",
        "  Stp = []   # [ th = 0.1_pre1, th = 0.2_pre2, ... , th = 0.9_pre9 ] number of elements = 9\n",
        "  Dtp = []   # [ th = min_pre1, th = 95%_pre2, ... , th = 99%_pre4 ] number of elements = 4\n",
        "  Str = []   # [ th = 0.1_rec1, th = 0.2_rec2, ... , th = 0.9_rec9 ] number of elements = 9\n",
        "  Dtr = []   # [ th = min_rec1, th = 95%_rec2, ... , th = 99%_rec4 ] number of elements = 4\n",
        "  new_y_pred = model.predict(data_set) # error\n",
        "  MD = get_MD(y_pred, new_y_pred, y_test)\n",
        "\n",
        "  for s in PMD_By_Static_Threshold :\n",
        "    Stp.append(get_PMD_Precision(MD, s))\n",
        "    Str.append(get_PMD_Recall(MD, s))\n",
        "\n",
        "  for d in PMD_By_Dynamic_Threshold :\n",
        "    Dtp.append(get_PMD_Precision(MD, d))\n",
        "    Dtr.append(get_PMD_Recall(MD, d))\n",
        "\n",
        "  return Stp, Dtp, Str, Dtr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIrGCTsIT0W2"
      },
      "source": [
        "def get_Avg_Result(lists) : #\n",
        "  x = len(lists[0]) # static = 9, dynamic = 4\n",
        "  y = len(lists)    # aggmentation, reduction = 4, rotate = 9\n",
        "  Avg = []\n",
        "\n",
        "  for i in range(x) :\n",
        "    temp = 0\n",
        "    for j in range(y) :\n",
        "      temp = temp + lists[j][i]\n",
        "    Avg.append(temp/y)\n",
        "  return Avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IstHpWWqaKbx"
      },
      "source": [
        "def validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_rate, rotated = False) : #\n",
        "\n",
        "  stp_Result = []\n",
        "  dtp_Result = []\n",
        "  str_Result = []\n",
        "  dtr_Result = []\n",
        "\n",
        "  for rate in list_of_rate :\n",
        "    if rotated :\n",
        "      data_set = rotate_img_set(x_test, rate)\n",
        "    else :\n",
        "      data_set = size_Adjust(x_test, rate)\n",
        "    data_set = np.array(data_set)\n",
        "\n",
        "    Stp, Dtp, Str, Dtr = get_Result(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, data_set, y_pred, y_test)\n",
        "    stp_Result.append(Stp)\n",
        "    dtp_Result.append(Dtp)\n",
        "    str_Result.append(Str)\n",
        "    dtr_Result.append(Dtr)\n",
        "\n",
        "  stp_Result = get_Avg_Result(stp_Result)\n",
        "  dtp_Result = get_Avg_Result(dtp_Result)\n",
        "  str_Result = get_Avg_Result(str_Result)\n",
        "  dtr_Result = get_Avg_Result(dtr_Result)\n",
        "  return stp_Result, dtp_Result, str_Result, dtr_Result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvNLJ7piWSqM"
      },
      "source": [
        "def print_Result(stp_Result, dtp_Result, str_Result, dtr_Result, comments, staticThreshold, dynamicThreshold) :\n",
        "  print(comments)\n",
        "  print(staticThreshold)\n",
        "  print(stp_Result)\n",
        "  print(str_Result)\n",
        "  print(dynamicThreshold)\n",
        "  print(dtp_Result)\n",
        "  print(dtr_Result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ldORRdSVA6G"
      },
      "source": [
        "list_of_ag_rate = [1.1, 1.2, 1.3, 1.4]\n",
        "list_of_rd_rate = [0.9, 0.8, 0.7, 0.6]\n",
        "list_of_degree = [10, 20, 30, 40, 50, 60 ,70, 80 ,90]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIjZQrrqVDHQ",
        "outputId": "20e5a8fa-b6e2-42c9-92c1-ef3922cd3a8c"
      },
      "source": [
        "rot_Stp, rot_Dtp, rot_Str, rot_Dtr = validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_degree, True)   ## rotated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rotate 10degree\n",
            "rotate 20degree\n",
            "rotate 30degree\n",
            "rotate 40degree\n",
            "rotate 50degree\n",
            "rotate 60degree\n",
            "rotate 70degree\n",
            "rotate 80degree\n",
            "rotate 90degree\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LO8k1sSVGDT",
        "outputId": "d7445632-5926-4dbb-ca25-53480b1784ca"
      },
      "source": [
        "ag_Stp, ag_Dtp, ag_Str, ag_Dtr = validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_ag_rate, False)    ## augmentation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "augmentation 1.1%\n",
            "augmentation 1.2%\n",
            "augmentation 1.3%\n",
            "augmentation 1.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GJeSp_xVIcI",
        "outputId": "326a4d55-6eeb-4a10-df2b-c1fad40f2ac1"
      },
      "source": [
        "rd_Stp, rd_Dtp, rd_Str, rd_Dtr = validation(PMD_By_Static_Threshold, PMD_By_Dynamic_Threshold, y_pred, y_test, list_of_rd_rate, False)   ## reduction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reduction 0.9%\n",
            "reduction 0.8%\n",
            "reduction 0.7%\n",
            "reduction 0.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz1I_yWxWm2l",
        "outputId": "eead08eb-1334-408e-e7ed-0d4189462349"
      },
      "source": [
        "print_Result(rot_Stp, rot_Dtp, rot_Str, rot_Dtr, \"Rotation\", staticThreshold, dynamicThreshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rotation\n",
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
            "[0.7840277777777778, 0.7989898989898989, 0.8039950062421971, 0.8218954248366013, 0.8477366255144033, 0.8333333333333333, 0.8677248677248678, 0.8333333333333335, 0.8444444444444444]\n",
            "[0.183358719945324, 0.1325836305577468, 0.10847642889693401, 0.08444624927574178, 0.07034201720697959, 0.04809779510363152, 0.02478384169450232, 0.013185722184296948, 0.005818265008916606]\n",
            "[0.74587244, 5.185324421156891, 5.125026945426301, 5.054967021244092]\n",
            "[0.8472222222222222, 0.0, 0.0, 0.0]\n",
            "[0.018291660620597158, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxaGucIFH305",
        "outputId": "b40c82f1-1816-47cf-94e8-8adce97cb0bf"
      },
      "source": [
        "print_Result(ag_Stp, ag_Dtp, ag_Str, ag_Dtr, \"Augmentation\", staticThreshold, dynamicThreshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmentation\n",
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
            "[0.39375000000000004, 0.4477272727272727, 0.4662921348314607, 0.4963235294117647, 0.4722222222222222, 0.4671052631578947, 0.5714285714285714, 0.7083333333333334, 0.9]\n",
            "[0.35451279360478627, 0.28908237232726164, 0.24726672986094317, 0.20444495831472514, 0.1497887493005382, 0.1022022528700734, 0.07149753518785587, 0.05126771749216397, 0.02697646130880407]\n",
            "[0.74587244, 5.185324421156891, 5.125026945426301, 5.054967021244092]\n",
            "[0.578125, 0.0, 0.0, 0.0]\n",
            "[0.05463598272689776, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXdBb1yEH3-s",
        "outputId": "75ff4b93-aef2-452d-e9d5-20cbd7d7ab4f"
      },
      "source": [
        "print_Result(rd_Stp, rd_Dtp, rd_Str, rd_Dtr, \"Reduction\", staticThreshold, dynamicThreshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reduction\n",
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
            "[0.5734375, 0.6159090909090909, 0.6292134831460674, 0.6580882352941176, 0.7083333333333334, 0.7171052631578947, 0.7857142857142858, 0.7708333333333334, 0.7]\n",
            "[0.48264163146759165, 0.3649867974867174, 0.3038977159880834, 0.252696333041978, 0.2187207977338355, 0.1574900809540589, 0.09923259914851035, 0.05423563473504211, 0.019041250417583824]\n",
            "[0.74587244, 5.185324421156891, 5.125026945426301, 5.054967021244092]\n",
            "[0.75, 0.0, 0.0, 0.0]\n",
            "[0.0716135286481572, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
